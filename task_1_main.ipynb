{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "task_1_main.ipynb",
      "provenance": []
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "48cf89f9bb96497aa1885022770a0551": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c0594a5bcf6c48f39c2e1fb96d56b9e8",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0af5f12aeaf5470a98be8b2093ca0eb1",
              "IPY_MODEL_d58e26c12d1f4d3c8bdbf80fc64224f8"
            ]
          }
        },
        "c0594a5bcf6c48f39c2e1fb96d56b9e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0af5f12aeaf5470a98be8b2093ca0eb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_9ebce26922d84a53a74f257b8f820da2",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 481,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 481,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2e20f4f985074e4583441a4c3164c2a4"
          }
        },
        "d58e26c12d1f4d3c8bdbf80fc64224f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9a9502bb82f24a0fb1e09ce0f426e0a8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 481/481 [00:00&lt;00:00, 2.58kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7b5c329d91914302a65230636f452eae"
          }
        },
        "9ebce26922d84a53a74f257b8f820da2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2e20f4f985074e4583441a4c3164c2a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9a9502bb82f24a0fb1e09ce0f426e0a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7b5c329d91914302a65230636f452eae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e3050f072b4f476d91b838765fcc90c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e938f222aa9a4e8bab885e71b1be142d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9b3a6c4767484d32b5015a39cf3fc5f3",
              "IPY_MODEL_088e02819104465eb954607426641730"
            ]
          }
        },
        "e938f222aa9a4e8bab885e71b1be142d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9b3a6c4767484d32b5015a39cf3fc5f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_fbcfab6bd3614819becc25f09d51d72a",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 501200538,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 501200538,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_21ac97bd12be47ff889282410406d11d"
          }
        },
        "088e02819104465eb954607426641730": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_29ef1b47c3fc4a9dba4c900bbd1d4ca8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 501M/501M [00:22&lt;00:00, 22.2MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5f439cd8ce00489abafe7e6e9a7df763"
          }
        },
        "fbcfab6bd3614819becc25f09d51d72a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "21ac97bd12be47ff889282410406d11d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "29ef1b47c3fc4a9dba4c900bbd1d4ca8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5f439cd8ce00489abafe7e6e9a7df763": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7630ab3c77a6407c98dc92a765d7f823": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ab095e5b0c7a45bcb9ead14ef239f751",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5668308b0254428aae67f7bc7ad49388",
              "IPY_MODEL_d85b40ca485e4c5287dee853900aef10"
            ]
          }
        },
        "ab095e5b0c7a45bcb9ead14ef239f751": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5668308b0254428aae67f7bc7ad49388": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a8b36bf1597f461ba44cc5be1e12134d",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 898823,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 898823,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_920527e15044491e9950934bdc2eed07"
          }
        },
        "d85b40ca485e4c5287dee853900aef10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_37c23170a5604fb5b7935abc1f6fb752",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 899k/899k [00:00&lt;00:00, 4.03MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c119a73f57864b3d869f951659f7fd77"
          }
        },
        "a8b36bf1597f461ba44cc5be1e12134d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "920527e15044491e9950934bdc2eed07": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "37c23170a5604fb5b7935abc1f6fb752": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c119a73f57864b3d869f951659f7fd77": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "79f6f959dfd548efaa3642b0340c06b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_002fe7e33c0740d3a2e005a3fc4f5aaa",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ec23e14555d7457293c6dc5b1bb2de95",
              "IPY_MODEL_b3d45f85ffe642009bc2c7b22bf743c3"
            ]
          }
        },
        "002fe7e33c0740d3a2e005a3fc4f5aaa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ec23e14555d7457293c6dc5b1bb2de95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a48614714c4849a8bafcdfcaebca1add",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 456318,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 456318,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_71be1cd2c80548aa8c144aaa17cccca9"
          }
        },
        "b3d45f85ffe642009bc2c7b22bf743c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c0456dfcfb314abebb88f0ca1f9bf5d6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 456k/456k [00:00&lt;00:00, 4.12MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_57452020634345d59f42cb1fab1afc95"
          }
        },
        "a48614714c4849a8bafcdfcaebca1add": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "71be1cd2c80548aa8c144aaa17cccca9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c0456dfcfb314abebb88f0ca1f9bf5d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "57452020634345d59f42cb1fab1afc95": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2TvyemfDlDmu"
      },
      "source": [
        "# NLP CW Task 1\n",
        "\n",
        "  - Approach 1, which can use use pre-trained embeddings / models\n",
        "  - Approach 2, which should not use any pre-trained embeddings or models\n",
        "\n",
        "#### Running your code:\n",
        "  - Your models should run automatically when running your colab file without further intervention\n",
        "  - For each task you should automatically output the performance of both models\n",
        "  - Your code should automatically download any libraries required\n",
        "\n",
        "#### Structure of your code:\n",
        "  - You are expected to use the 'train', 'eval' and 'model_performance' functions, although you may edit these as required\n",
        "  - Otherwise there are no restrictions on what you can do in your code\n",
        "\n",
        "#### Documentation:\n",
        "  - You are expected to produce a .README file summarising how you have approached both tasks\n",
        "  - Your .README file should explain how to replicate the different experiments mentioned in your report"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LRWFk-kelDoA"
      },
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, random_split\n",
        "from collections import Counter\n",
        "import nltk\n",
        "import string\n",
        "import torchtext\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import binned_statistic\n",
        "from scipy.spatial.distance import euclidean, cosine\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "import codecs\n",
        "from tqdm import tqdm\n",
        "import torch.nn.functional as F\n",
        "import re\n",
        "import spacy"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vk6g6430Lsen"
      },
      "source": [
        "# Get pretrained GloVe embeddings\n",
        "glove = torchtext.vocab.GloVe(name='6B', dim=50)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "lJCEYZNOleKm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6bf3e3b1-98ac-42bc-edbb-92a368a9b6ec"
      },
      "source": [
        "# Install packages that Colab does not provide automatically\n",
        "!pip -q install transformers\n",
        "from transformers import RobertaTokenizer, RobertaModel, BertPreTrainedModel, DistilBertModel, DistilBertTokenizer\n",
        "\n",
        "# Download stopwords\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Get test and train data files\n",
        "if not os.path.exists('dev.csv'):\n",
        "  !wget -q --show-progress https://raw.githubusercontent.com/matt-malarkey/nlp-cw-data/master/dev.csv\n",
        "  !wget -q --show-progress https://raw.githubusercontent.com/matt-malarkey/nlp-cw-data/master/train.csv"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "dev.csv             100%[===================>] 211.85K  --.-KB/s    in 0.03s   \n",
            "train.csv           100%[===================>] 925.70K  --.-KB/s    in 0.07s   \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X09jt8VRlDoM"
      },
      "source": [
        "# Setting random seed and device\n",
        "SEED = 1\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AqhlzLl6lDoO"
      },
      "source": [
        "# Load data\n",
        "train_df = pd.read_csv('train.csv')\n",
        "test_df = pd.read_csv('dev.csv')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3RCmF7xulDoP"
      },
      "source": [
        "# Number of epochs\n",
        "epochs = 10\n",
        "\n",
        "# Proportion of training data for train compared to dev\n",
        "train_proportion = 0.8"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qAgZW6K1lDoR"
      },
      "source": [
        "# We define our training loop\n",
        "def train(train_iter, dev_iter, model, number_epoch, optimizer):\n",
        "  \"\"\"\n",
        "  Training loop for the model, which calls on eval to evaluate after each epoch\n",
        "  \"\"\"\n",
        "\n",
        "  print(\"Training model.\")\n",
        "\n",
        "  loss_fn = nn.MSELoss()\n",
        "  loss_fn = loss_fn.to(device)\n",
        "\n",
        "  performance_stats = []\n",
        "\n",
        "  for epoch in range(1, number_epoch+1):\n",
        "    model.train()\n",
        "\n",
        "    epoch_loss = 0\n",
        "    epoch_sse = 0\n",
        "    no_observations = 0  # Observations used for training so far\n",
        "\n",
        "    for batch in train_iter:\n",
        "      ids = batch['ids'].to(device).squeeze()\n",
        "      mask = batch['mask'].to(device).squeeze()\n",
        "      target = batch['target'].to(device, dtype=torch.float)\n",
        "      extra_features = batch['extra_features'].to(device)\n",
        "\n",
        "      predictions = model(ids, mask, extra_features).squeeze(1)\n",
        "      optimizer.zero_grad()\n",
        "      loss = loss_fn(predictions, target)\n",
        "\n",
        "      no_observations = no_observations + target.shape[0]\n",
        "      sse, __ = model_performance(predictions.detach().cpu().numpy(), target.detach().cpu().numpy())\n",
        "\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      epoch_loss += loss.item()*target.shape[0]\n",
        "      epoch_sse += sse\n",
        "\n",
        "    valid_loss, valid_mse, __, __ = eval(dev_iter, model)\n",
        "\n",
        "    epoch_loss, epoch_mse = epoch_loss / no_observations, epoch_sse / no_observations\n",
        "    performance_stats.append((valid_loss, valid_mse**0.5))\n",
        "    print(f'| Epoch: {epoch:02} | Train Loss: {epoch_loss:.2f} | Train MSE: {epoch_mse:.2f} | Train RMSE: {epoch_mse**0.5:.2f} | \\\n",
        "    Val. Loss: {valid_loss:.2f} | Val. MSE: {valid_mse:.2f} |  Val. RMSE: {valid_mse**0.5:.2f} |')\n",
        "\n",
        "  return performance_stats"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NzXeDgHmlDob"
      },
      "source": [
        "# We evaluate performance on our dev set\n",
        "def eval(data_iter, model):\n",
        "  \"\"\"\n",
        "  Evaluating model performance on the dev set\n",
        "  \"\"\"\n",
        "  model.eval()\n",
        "  epoch_loss = 0\n",
        "  epoch_sse = 0\n",
        "  pred_all = []\n",
        "  trg_all = []\n",
        "  no_observations = 0\n",
        "  loss_fn = nn.MSELoss()\n",
        "  loss_fn = loss_fn.to(device)\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for batch in data_iter:\n",
        "      ids = batch['ids'].to(device).squeeze()\n",
        "      mask = batch['mask'].to(device).squeeze()\n",
        "      target = batch['target'].to(device, dtype=torch.float)\n",
        "      extra_features = batch['extra_features'].to(device)\n",
        "\n",
        "      predictions = model(ids, mask, extra_features).squeeze(1)\n",
        "\n",
        "      loss = loss_fn(predictions, target)\n",
        "\n",
        "      # We get the mse\n",
        "      pred, trg = predictions.detach().cpu().numpy(), target.detach().cpu().numpy()\n",
        "      sse, __ = model_performance(pred, trg)\n",
        "\n",
        "      no_observations = no_observations + target.shape[0]\n",
        "      epoch_loss += loss.item()*target.shape[0]\n",
        "      epoch_sse += sse\n",
        "      pred_all.extend(pred)\n",
        "      trg_all.extend(trg)\n",
        "\n",
        "  return epoch_loss/no_observations, epoch_sse/no_observations, np.array(pred_all), np.array(trg_all)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_22fHHElDog"
      },
      "source": [
        "# How we print the model performance\n",
        "def model_performance(output, target, print_output=False):\n",
        "  \"\"\"\n",
        "  Returns SSE and MSE per batch (printing the MSE and the RMSE)\n",
        "  \"\"\"\n",
        "  sq_error = (output - target)**2\n",
        "\n",
        "  sse = np.sum(sq_error)\n",
        "  mse = np.mean(sq_error)\n",
        "  rmse = np.sqrt(mse)\n",
        "\n",
        "  if print_output:\n",
        "    print(f'| MSE: {mse:.2f} | RMSE: {rmse:.2f} |')\n",
        "\n",
        "  return sse, mse"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jyew1QfTSuzM"
      },
      "source": [
        "# Data Analysis\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FhhQ12OmSzD6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "41b4e1e2-d7f3-4848-f9d9-04392b7597d6"
      },
      "source": [
        "# Basic Stats\r\n",
        "num_headlines = len(train_df)\r\n",
        "max_len = max(train_df['original'].apply(len))\r\n",
        "avg_score = train_df['meanGrade'].mean()\r\n",
        "print(f'Number of Headlines: {num_headlines}, Max Headline Length: {max_len}, Avg Score: {avg_score:.2f}')\r\n",
        "\r\n",
        "# Most common words\r\n",
        "stopwords = nltk.corpus.stopwords.words('english')\r\n",
        "most_common_words = Counter(\" \".join(train_df['original']).split()).most_common(100)\r\n",
        "stopwords.append(string.punctuation)\r\n",
        "most_common_words = [(word, count) for (word, count) in most_common_words if word not in stopwords and word.isalpha()][:5]\r\n",
        "print(f'Most common words: {most_common_words}')\r\n",
        "\r\n",
        "# Analysis of Trump Headlines\r\n",
        "trump_headlines = train_df[train_df['original'].str.lower().str.contains('trump')]\r\n",
        "num_headlines_with_trump = len(trump_headlines)\r\n",
        "trump_avg_score = trump_headlines['meanGrade'].mean()\r\n",
        "prob_headline_contains_trump = num_headlines_with_trump / num_headlines\r\n",
        "trump_value_counts = trump_headlines['meanGrade'].value_counts(bins=3)\r\n",
        "trump_proportion_gt_one = (trump_value_counts[2] + trump_value_counts[3]) * 100 / num_headlines_with_trump\r\n",
        "print(f'Headlines with Trump: {prob_headline_contains_trump * 100:.2f}%, Avg Score: {trump_avg_score:.2f}')\r\n",
        "print(f'Proportion of Trump Headlines with score > 1: {trump_proportion_gt_one:.2f}%')\r\n",
        "\r\n",
        "# Analysis of word similarity and length of headlines\r\n",
        "semantic_similarity_data = []\r\n",
        "sentence_similarity_data = []\r\n",
        "levenshtein_similarity_data = []\r\n",
        "headline_length_data = []\r\n",
        "\r\n",
        "for row in train_df.itertuples():\r\n",
        "  all_words = row.original.split(' ')\r\n",
        "  headline_length_data.append((len(all_words), row.meanGrade))\r\n",
        "  sentence_vec = torch.zeros((1,50))\r\n",
        "  for i, word in enumerate(all_words):\r\n",
        "    if len(word) > 2 and word[0] == '<' and word[-2] == '/' and word[-1] == '>' :\r\n",
        "      word = word[1:-2].lower()\r\n",
        "      original_word_vec = glove[word].unsqueeze(0)\r\n",
        "      edited_word_vec = glove[row.edit.lower()].unsqueeze(0)\r\n",
        "      semantic_distance = torch.cosine_similarity(original_word_vec, edited_word_vec).item() \r\n",
        "      levenshtein_distance = nltk.edit_distance(word, row.edit.lower())\r\n",
        "      semantic_similarity_data.append((semantic_distance, row.meanGrade))\r\n",
        "      levenshtein_similarity_data.append((levenshtein_distance, row.meanGrade))\r\n",
        "    else:\r\n",
        "      sentence_vec += glove[word.lower()].unsqueeze(0)\r\n",
        "    \r\n",
        "    if i == len(all_words) - 1:\r\n",
        "      sentence_semantic_distance = torch.cosine_similarity(sentence_vec, edited_word_vec)\r\n",
        "      sentence_similarity_data.append((sentence_semantic_distance, row.meanGrade))\r\n",
        "\r\n",
        "\r\n",
        "# Analysis of # of clause separators\r\n",
        "separators_data = []\r\n",
        "for i in range(len(train_df['original'])):\r\n",
        "  matches = re.findall(\"[;,:(...)]\", train_df['original'][i])\r\n",
        "  separators_data.append((len(matches), train_df['meanGrade'][i]))\r\n",
        "\r\n",
        "# Plot word similarity vs meanGrade\r\n",
        "plt.figure(figsize=(15, 10))\r\n",
        "plt.subplot(2, 3, 1)\r\n",
        "mean_stat_similarity = binned_statistic(*zip(*semantic_similarity_data), bins=6, range=(-0.5, 1.0))\r\n",
        "plt.plot(mean_stat_similarity.bin_edges[:-1] + 0.125, mean_stat_similarity.statistic)\r\n",
        "plt.xlabel('Cosine Distance')\r\n",
        "plt.ylabel('Avg Score')\r\n",
        "plt.title('Semantic similarity vs meanGrade')\r\n",
        "\r\n",
        "# Levenshtein distance vs meanGrade\r\n",
        "plt.subplot(2, 3, 2)\r\n",
        "mean_stat_similarity = binned_statistic(*zip(*levenshtein_similarity_data), bins=6)\r\n",
        "plt.plot(mean_stat_similarity.bin_edges[:-1] + 0.125, mean_stat_similarity.statistic)\r\n",
        "plt.xlabel('Levenshtein Distance')\r\n",
        "plt.ylabel('Avg Score')\r\n",
        "plt.title('Word spelling similarity vs meanGrade')\r\n",
        "\r\n",
        "# Semantic similarity of word to headline vs meanGrade\r\n",
        "plt.subplot(2, 3, 3)\r\n",
        "mean_stat_similarity = binned_statistic(*zip(*sentence_similarity_data), bins=6)\r\n",
        "plt.plot(mean_stat_similarity.bin_edges[:-1] + 0.125, mean_stat_similarity.statistic)\r\n",
        "plt.xlabel('Cosine Distance')\r\n",
        "plt.ylabel('Avg Score')\r\n",
        "plt.title('Semantic similarity of word to headline vs meanGrade')\r\n",
        "\r\n",
        "# Plot clause separator count vs meanGrade\r\n",
        "plt.subplot(2, 3, 4)\r\n",
        "plt.plot()\r\n",
        "mean_stat_seps = binned_statistic(*zip(*separators_data), bins=6)\r\n",
        "plt.plot(mean_stat_seps.bin_edges[:-1], mean_stat_seps.statistic)\r\n",
        "plt.xlabel('Number of Clause Separators')\r\n",
        "plt.ylabel('Avg Score')\r\n",
        "plt.title('Clause Separator Count vs meanGrade')\r\n",
        "\r\n",
        "# Plot headline length vs meanGrade\r\n",
        "plt.subplot(2, 3, 5)\r\n",
        "mean_stat_headline_len = binned_statistic(*zip(*headline_length_data), bins=30, range=(0, 30))\r\n",
        "plt.plot(mean_stat_headline_len.bin_edges[:-1], mean_stat_headline_len.statistic)\r\n",
        "plt.xlabel('Number of Words')\r\n",
        "plt.ylabel('Avg Score')\r\n",
        "plt.title('Headline Length vs meanGrade')\r\n",
        "\r\n",
        "plt.show()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of Headlines: 9652, Max Headline Length: 146, Avg Score: 0.94\n",
            "Most common words: [('Trump', 3320), ('The', 557), ('House', 488), ('says', 483), ('Donald', 356)]\n",
            "Headlines with Trump: 39.11%, Avg Score: 1.02\n",
            "Proportion of Trump Headlines with score > 1: 42.38%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-ccd2af60870f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m       \u001b[0mlevenshtein_similarity_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlevenshtein_distance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeanGrade\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m       \u001b[0msentence_vec\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mglove\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_words\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'glove' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "cenE48y9leKo"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "2spyhNrBleKo"
      },
      "source": [
        "# Pattern to match words and multiword tags\n",
        "# See https://regex101.com/r/a2cWZL/1 for example\n",
        "# TOKEN_PATTERN = re.compile(\"[A-Za-z#]+|<[A-Za-z#]+\\s[A-Za-z]+\\/>\")\n",
        "\n",
        "# Patten to match only words\n",
        "TOKEN_PATTERN = re.compile(\"\\w+\")\n",
        "CLAUSE_SEPS = re.compile(\"[;,:(...)]\")\n",
        "\n",
        "# TODO: processing of:\n",
        "# - hashtags,\n",
        "# - words with a \"-\" in between them\n",
        "# - punctuation\n",
        "# - entity names\n",
        "\n",
        "def tokenize(sentence):\n",
        "  return TOKEN_PATTERN.findall(sentence)\n",
        "\n",
        "# Remove angle brackets and lowercase\n",
        "def preprocess(word):\n",
        "  if len(word) > 2 and word[0] == '<' and word[-2] == '/' and word[-1] == '>' :\n",
        "    word = word[1:-2]\n",
        "  return word.lower()\n",
        "\n",
        "def create_vocab(data):\n",
        "  \"\"\"\n",
        "  Creating a corpus of all the tokens used\n",
        "  \"\"\"\n",
        "  # Let us put the tokenized corpus in a list\n",
        "  tokenized_corpus = [[preprocess(t) for t in tokenize(s)] for s in data]\n",
        "\n",
        "  # Create single list of all vocabulary\n",
        "  vocabulary = []\n",
        "  for sentence in tokenized_corpus:\n",
        "    for token in sentence:\n",
        "      if token not in vocabulary:\n",
        "        vocabulary.append(token)\n",
        "\n",
        "  return vocabulary, tokenized_corpus\n",
        "\n",
        "# Extra features:\n",
        "# [0] - binary if 'Trump' in headline\n",
        "# [1] - length of headline          <--- will passing as a feature help bc all headlines are padded?\n",
        "# [3] - number of clause separators: elipsis, commas, colons or semi colons\n",
        "# other features: avg word length?\n",
        "EXTRA_FEATURES = 3\n",
        "def extract_features(raw_headline):\n",
        "  return [\n",
        "    int('Trump' in raw_headline), \n",
        "    len(raw_headline),\n",
        "    len(CLAUSE_SEPS.findall(raw_headline))\n",
        "  ]"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "aoC2hQrNleKp"
      },
      "source": [
        "# Inherits from Dataset class so the DataLoader can use it\n",
        "class Task1Dataset(Dataset):\n",
        "\n",
        "  def __init__(self, tokenizer, train_data, labels):\n",
        "    self.x_train = train_data\n",
        "    self.y_train = labels\n",
        "    self.tokenizer = tokenizer\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.y_train)\n",
        "\n",
        "  def __getitem__(self, item):\n",
        "    # Preprocess headline before embedding\n",
        "    headline = self.x_train[item]\n",
        "    # processed_headline = ' '.join([preprocess(t) for t in tokenize(headline)])\n",
        "    processed_headline = [preprocess(t) for t in tokenize(headline)]\n",
        "\n",
        "    target = self.y_train[item]\n",
        "\n",
        "    # Use is_split_into_words=True to allow for our own tokenizing\n",
        "    # - stops encode_plus splitting up unknown words into multiple parts\n",
        "    encoding = self.tokenizer.encode_plus(processed_headline, return_tensors='pt',\n",
        "                                          padding='max_length', truncation=True,\n",
        "                                          max_length=128, pad_to_max_length=True,\n",
        "                                          is_split_into_words=True)\n",
        "    ids = encoding['input_ids']\n",
        "    mask = encoding['attention_mask']\n",
        "\n",
        "    extra_features = extract_features(headline)\n",
        "\n",
        "    return {\n",
        "      'ids': torch.tensor(ids),\n",
        "      'mask': torch.tensor(mask),\n",
        "      'target': torch.tensor(target),\n",
        "      'extra_features': torch.tensor(extra_features)\n",
        "    }"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sWaxTh2UlDoy"
      },
      "source": [
        "class BertRegressionModel(nn.Module):\n",
        "  def __init__(self, model_name):\n",
        "    super(BertRegressionModel, self).__init__()\n",
        "\n",
        "    if model_name == 'distilbert':\n",
        "      self.bert = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
        "    elif model_name == 'roberta':\n",
        "      self.bert = RobertaModel.from_pretrained('roberta-base')\n",
        "    \n",
        "    self.num_extra_features = EXTRA_FEATURES\n",
        "    self.linear1 = nn.Linear(768, 32)\n",
        "    self.linear2 = nn.Linear(32 + self.num_extra_features, 1)\n",
        "\n",
        "  def forward(self, ids, mask, extra_features):\n",
        "    embeddings = self.bert(input_ids=ids, attention_mask=mask)[0]\n",
        "    x = self.linear1(embeddings[:, 0])\n",
        "    concat_features = torch.cat([x, extra_features], dim=1)\n",
        "    x = self.linear2(concat_features)\n",
        "    return x"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g190qtchuI2W"
      },
      "source": [
        "### Approach 1: Using pre-trained representations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "bp9d32sOlDo6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "802cf3df-8c6e-4ee7-c683-3812a8f105e4"
      },
      "source": [
        "BATCH_SIZE = 32\n",
        "\n",
        "# Initialise chosen BERT model and tokenizer\n",
        "# To change the model to use Roberta, pass in 'roberta' to the regression model\n",
        "# and uncomment the tokenizer below.\n",
        "model = BertRegressionModel('distilbert').to(device)\n",
        "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "# tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
        "\n",
        "# Set training and test data\n",
        "training_data = train_df['original']\n",
        "training_labels = train_df['meanGrade']\n",
        "test_data = test_df['original']\n",
        "train_and_dev = Task1Dataset(tokenizer, training_data, training_labels)\n",
        "\n",
        "# Split training data into train and dev sets\n",
        "train_examples = round(len(train_and_dev)*train_proportion)\n",
        "dev_examples = len(train_and_dev) - train_examples\n",
        "train_dataset, dev_dataset = random_split(train_and_dev, (train_examples, dev_examples))\n",
        "\n",
        "# Create data loaders\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, shuffle=True, batch_size=BATCH_SIZE)\n",
        "dev_loader = torch.utils.data.DataLoader(dev_dataset, batch_size=BATCH_SIZE)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'torch.utils.data.dataset.Subset'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wFxhZKMC783t",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 625,
          "referenced_widgets": [
            "48cf89f9bb96497aa1885022770a0551",
            "c0594a5bcf6c48f39c2e1fb96d56b9e8",
            "0af5f12aeaf5470a98be8b2093ca0eb1",
            "d58e26c12d1f4d3c8bdbf80fc64224f8",
            "9ebce26922d84a53a74f257b8f820da2",
            "2e20f4f985074e4583441a4c3164c2a4",
            "9a9502bb82f24a0fb1e09ce0f426e0a8",
            "7b5c329d91914302a65230636f452eae",
            "e3050f072b4f476d91b838765fcc90c7",
            "e938f222aa9a4e8bab885e71b1be142d",
            "9b3a6c4767484d32b5015a39cf3fc5f3",
            "088e02819104465eb954607426641730",
            "fbcfab6bd3614819becc25f09d51d72a",
            "21ac97bd12be47ff889282410406d11d",
            "29ef1b47c3fc4a9dba4c900bbd1d4ca8",
            "5f439cd8ce00489abafe7e6e9a7df763",
            "7630ab3c77a6407c98dc92a765d7f823",
            "ab095e5b0c7a45bcb9ead14ef239f751",
            "5668308b0254428aae67f7bc7ad49388",
            "d85b40ca485e4c5287dee853900aef10",
            "a8b36bf1597f461ba44cc5be1e12134d",
            "920527e15044491e9950934bdc2eed07",
            "37c23170a5604fb5b7935abc1f6fb752",
            "c119a73f57864b3d869f951659f7fd77",
            "79f6f959dfd548efaa3642b0340c06b9",
            "002fe7e33c0740d3a2e005a3fc4f5aaa",
            "ec23e14555d7457293c6dc5b1bb2de95",
            "b3d45f85ffe642009bc2c7b22bf743c3",
            "a48614714c4849a8bafcdfcaebca1add",
            "71be1cd2c80548aa8c144aaa17cccca9",
            "c0456dfcfb314abebb88f0ca1f9bf5d6",
            "57452020634345d59f42cb1fab1afc95"
          ]
        },
        "outputId": "ec713075-e90d-49a8-8d10-a26caca95a00"
      },
      "source": [
        "# Do the training\n",
        "distil_model = BertRegressionModel('distilbert').to(device)\n",
        "optimizer_distil = torch.optim.Adam(distil_model.parameters())\n",
        "tokenizer_distil = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "\n",
        "roberta_model = BertRegressionModel('roberta').to(device)\n",
        "optimizer_roberta = torch.optim.Adam(roberta_model.parameters())\n",
        "tokenizer_roberta = RobertaTokenizer.from_pretrained('roberta-base')\n",
        "\n",
        "performance_stats_roberta = train(train_loader, dev_loader, roberta_model, epochs, optimizer_roberta)\n",
        "performance_stats_distil = train(train_loader, dev_loader, distil_model, epochs, optimizer_distil)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "48cf89f9bb96497aa1885022770a0551",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=481.0, style=ProgressStyle(description_â€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e3050f072b4f476d91b838765fcc90c7",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=501200538.0, style=ProgressStyle(descriâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7630ab3c77a6407c98dc92a765d7f823",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=898823.0, style=ProgressStyle(descriptiâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "79f6f959dfd548efaa3642b0340c06b9",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=456318.0, style=ProgressStyle(descriptiâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Training model.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:32: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-97-540c03fba671>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mtokenizer_roberta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRobertaTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'roberta-base'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mperformance_stats_roberta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroberta_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_roberta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mperformance_stats_distil\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistil_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_distil\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-83-d4fd5fd36715>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_iter, dev_iter, model, number_epoch, optimizer)\u001b[0m\n\u001b[1;32m     32\u001b[0m       \u001b[0msse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_performance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m       \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m       \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    130\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UJQ1bqH13ZXx"
      },
      "source": [
        "# Save models\r\n",
        "torch.save(roberta_model, 'roberta-model.pt')\r\n",
        "torch.save(distil_model, 'distilbert-model.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "DSrlCvKZWOZW",
        "outputId": "db5dd50a-dd5e-4649-90a7-fb4358852acc"
      },
      "source": [
        "from google.colab import files\r\n",
        "files.download('roberta-model.pt') "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_becf5d8f-520d-4055-9c40-feb061f2b6bc\", \"roberta-model.pt\", 498789915)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "T_YyhDlPzSaP",
        "outputId": "42e298bb-3aac-4277-ffb5-ce811967c38b"
      },
      "source": [
        "# Plot losses for both pre trained models\r\n",
        "epoch_losses_1, rmse_1 = zip(*performance_stats_distil)\r\n",
        "epoch_losses_2, rmse_2 = zip(*performance_stats_roberta)\r\n",
        "x = np.arange(epochs) + 1\r\n",
        "\r\n",
        "plt.figure(figsize=(10, 5))\r\n",
        "\r\n",
        "plt.subplot(1, 2, 1)\r\n",
        "plt.plot(x, epoch_losses_1, label='distil-bert')\r\n",
        "plt.plot(x, epoch_losses_2, label='roberta')\r\n",
        "plt.legend(loc='upper right')\r\n",
        "plt.xlabel('Epoch')\r\n",
        "plt.ylabel('Loss')\r\n",
        "plt.title('Pre-trained model losses')\r\n",
        "\r\n",
        "plt.subplot(1, 2, 2)\r\n",
        "plt.plot(x, rmse_1, label='distil-bert')\r\n",
        "plt.plot(x, rmse_2, label='roberta')\r\n",
        "plt.legend(loc='upper right')\r\n",
        "plt.xlabel('Epoch')\r\n",
        "plt.ylabel('RMSE')\r\n",
        "plt.title('Pre-trained model RMSE')\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TSHxwXoviuma"
      },
      "source": [
        "### Aside: Using NER for Feature Engineering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFu6FcpAiuTo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        },
        "outputId": "3c2df66f-ea14-40c5-8cba-0a0024f5963c"
      },
      "source": [
        "# Load spacy\n",
        "ner = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# ps = nltk.stem.porter.PorterStemmer()\n",
        "# print([ps.stem(word) for word in txt])\n",
        "\n",
        "# lem = nltk.stem.wordnet.WordNetLemmatizer()\n",
        "# print([lem.lemmatize(word) for word in txt])\n",
        "\n",
        "# Test sentences\n",
        "sents = [\n",
        "  \"#WomensMarch against <Donald Trump/> around the world\",\n",
        "  \"' Disappeared ' Lawyer investigating in Egypt the death of Cambridge student , Giulio Regeni , re-appears in court , under <charges/> \",\n",
        "  \"' This is not the end ' : <John McCain/> warns Trump , torches Rand Paul on Syria missile strikes\"\n",
        "]\n",
        "\n",
        "# Map entities to an index, for representing as 1HV\n",
        "entities = []\n",
        "\n",
        "# Build model\n",
        "for s in sents:\n",
        "  pre_s = ' '.join([preprocess(t) for t in tokenize(s)])\n",
        "  r_sub = re.sub(r'[^\\w\\s]', '', str(s))\n",
        "\n",
        "  print()\n",
        "  print(f\"Original:       {s}\")\n",
        "  print(f\"Preprocessed:   {pre_s}\")\n",
        "  print(f\"New regex:      {r_sub}\")\n",
        "  print(f\"BERT Tokenized: {tokenizer.tokenize(pre_s)}\")\n",
        "\n",
        "  # NER\n",
        "  doc = ner(r_sub)\n",
        "  spacy.displacy.render(doc, style=\"ent\", jupyter=True)\n",
        "\n",
        "  # TODO: try and merge 'Trump' and 'Donald Trump' for PERSON entities\n",
        "  for e in doc.ents:\n",
        "    if e not in entities:\n",
        "        entities.append(e)\n",
        "\n",
        "  print()\n",
        "  \n",
        "ent2idx = {e: idx for (idx, e) in enumerate(entities)}\n",
        "print(ent2idx)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Original:       #WomensMarch against <Donald Trump/> around the world\n",
            "Preprocessed:   womensmarch against donald trump around the world\n",
            "New regex:      WomensMarch against Donald Trump around the world\n",
            "BERT Tokenized: ['women', '##sma', '##rch', 'against', 'donald', 'trump', 'around', 'the', 'world']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">WomensMarch against \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Donald Trump\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " around the world</div></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Original:       ' Disappeared ' Lawyer investigating in Egypt the death of Cambridge student , Giulio Regeni , re-appears in court , under <charges/> \n",
            "Preprocessed:   disappeared lawyer investigating in egypt the death of cambridge student giulio regeni re appears in court under charges\n",
            "New regex:       Disappeared  Lawyer investigating in Egypt the death of Cambridge student  Giulio Regeni  reappears in court  under charges \n",
            "BERT Tokenized: ['disappeared', 'lawyer', 'investigating', 'in', 'egypt', 'the', 'death', 'of', 'cambridge', 'student', 'gi', '##ulio', 'reg', '##eni', 're', 'appears', 'in', 'court', 'under', 'charges']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\"> Disappeared  \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Lawyer\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " investigating in \n",
              "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Egypt\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
              "</mark>\n",
              " the death of \n",
              "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Cambridge\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
              "</mark>\n",
              " student  \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Giulio Regeni\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              "  reappears in court  under charges </div></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Original:       ' This is not the end ' : <John McCain/> warns Trump , torches Rand Paul on Syria missile strikes\n",
            "Preprocessed:   this is not the end john mccain warns trump torches rand paul on syria missile strikes\n",
            "New regex:       This is not the end   John McCain warns Trump  torches Rand Paul on Syria missile strikes\n",
            "BERT Tokenized: ['this', 'is', 'not', 'the', 'end', 'john', 'mccain', 'warns', 'trump', 'torches', 'rand', 'paul', 'on', 'syria', 'missile', 'strikes']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\"> This is not the end   \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    John McCain\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " warns \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Trump\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              "  torches \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Rand Paul\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " on \n",
              "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Syria\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
              "</mark>\n",
              " missile strikes</div></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "{Donald Trump: 0, Lawyer: 1, Egypt: 2, Cambridge: 3, Giulio Regeni: 4, John McCain: 5, Trump: 6, Rand Paul: 7, Syria: 8}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dID3NDP3cxwn"
      },
      "source": [
        "## Approach 2\n",
        "No pre-trained represetations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m6S1eTHJK9Bl"
      },
      "source": [
        "class Task1DatasetNN(Dataset):\n",
        "\n",
        "  def __init__(self, train_data, labels):\n",
        "    self.x_train = train_data\n",
        "    self.y_train = labels\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.y_train)\n",
        "\n",
        "  def __getitem__(self, item):\n",
        "    headline = self.x_train[item]\n",
        "    # processed_headline = ' '.join([preprocess(t) for t in tokenize(headline)])\n",
        "    processed_headline = [preprocess(t) for t in tokenize(headline)]\n",
        "\n",
        "    # TODO\n",
        "    vectorized_headline = processed_headline\n",
        "\n",
        "    target = self.y_train[item]\n",
        "    extra_features = extract_features(headline)\n",
        "\n",
        "    return {\n",
        "      'encoding': vectorized_headline,\n",
        "      'target': torch.tensor(target),\n",
        "      'extra_features': torch.tensor(extra_features)\n",
        "    }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gmzCY5FcLCav"
      },
      "source": [
        "# Set training and test data\n",
        "training_data = train_df['original']\n",
        "training_labels = train_df['meanGrade']\n",
        "test_data = test_df['original']\n",
        "train_and_dev = Task1DatasetNN(training_data, training_labels)\n",
        "\n",
        "# Split training data into train and dev sets\n",
        "train_examples = round(len(training_data)*train_proportion)\n",
        "dev_examples = len(training_data) - train_examples\n",
        "train_dataset, dev_dataset = random_split(training_data, (train_examples, dev_examples))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9pnrZAQ_EtCn"
      },
      "source": [
        "# Remove punctuation\n",
        "def remove_punc(dataset):\n",
        "  return [re.sub(r'[^\\w\\s]', '', s) for s in dataset]\n",
        "\n",
        "# Get NER lookup table from training data\n",
        "def get_entity2idx(dataset):\n",
        "  entities = {}\n",
        "  idx = 0\n",
        "  for s in dataset:\n",
        "    doc = ner(s)\n",
        "    for e in doc.ents:\n",
        "      e = str(e)\n",
        "      if e not in entities:\n",
        "        entities[e] = idx\n",
        "        idx+=1\n",
        "  return entities\n",
        "\n",
        "# Map headlines to list of entity IDs\n",
        "def get_entity_features(dataset, e2i):\n",
        "  return [[e2i[str(e)] for e in ner(s).ents] for s in dataset]\n",
        "\n",
        "# Tokenize, lowercase, remove stop words\n",
        "def tokenize_no_stopwords(dataset):\n",
        "  stopwords = nltk.corpus.stopwords.words('english')\n",
        "  return [[w.lower() for w in s.split(' ') if w not in stopwords and len(w)] for s in dataset]\n",
        "\n",
        "def tokenize2(dataset):\n",
        "  return [[w.lower() for w in s.split(' ')] for s in dataset]\n",
        "\n",
        "# Restrict corpus size for experiments\n",
        "corpus = remove_punc(train_dataset[:25])\n",
        "tokenized_corpus = tokenize2(train_dataset)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FQc2FZaISoGO",
        "outputId": "f03a51b9-6411-4763-869f-3da3e6a19dc9"
      },
      "source": [
        "e2i = get_entity2idx(corpus)\n",
        "print(e2i)\n",
        "print(type(e2i['Trump']))\n",
        "efs = get_entity_features(corpus, e2i)\n",
        "print(efs[:10])"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'Hawaii': 0, 'Trump': 1, 'Michigan': 2, '3 days': 3, 'Syria': 4, 'HB2 Repeal': 5, 'North Carolina': 6, 'Puerto Rico': 7, '133': 8, 's': 9, 'FEMA': 10, 'Islamists': 11, 'North Korea': 12, 'Africa': 13, 'Nigerian': 14, 'Today': 15, 'Turkey': 16, 'Turkish': 17, 'Erdogan': 18, 'Breitbart News': 19, 'America': 20, 'ESPN': 21, 'Wilbur Ross': 22, 'Saudi Arabia': 23, 'Texas': 24, 'Republican': 25, 'Nikki Haley': 26, 'Michael Wolff': 27, 'California': 28, 'Republicans': 29, 'Trump Vows North Korea': 30, 'first': 31, 'James Comey': 32, 'CIA': 33, 'Flynn': 34, 'Russians': 35, 'The Halfhearted Opposition': 36, 'GOP': 37, 'Maddow': 38, 'Iowa': 39, 'Ronny Jackson': 40, 'Trump s': 41, 'Veterans Affairs': 42}\n",
            "<class 'int'>\n",
            "[[0, 1], [1], [2, 3], [4], [], [5, 6], [], [7, 8, 1, 9, 10], [11], []]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4LWut1gtXGQN"
      },
      "source": [
        "class FFNN(nn.Module):\n",
        "  def __init__(self, embedding_dim, hidden_dim, vocab_size, num_classes):  \n",
        "    super(FFNN, self).__init__()\n",
        "    \n",
        "    # embedding (lookup layer) layer\n",
        "    # padding_idx argument makes sure that the 0-th token in the vocabulary\n",
        "    # is used for padding purposes i.e. its embedding will be a 0-vector\n",
        "    self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
        "    \n",
        "    # hidden layer\n",
        "    self.fc1 = nn.Linear(embedding_dim, hidden_dim)\n",
        "    \n",
        "    # activation\n",
        "    self.relu1 = nn.ReLU()\n",
        "    \n",
        "    # output layer\n",
        "    self.fc2 = nn.Linear(hidden_dim, num_classes)  \n",
        "  \n",
        "  # Average sentence embedding (ignoring padding)\n",
        "  # Maps embedded : (batch_size, max_sent_len, embedding_dim) => (batch_size, embeddind_dim)\n",
        "  def average_embedding(self, embedded):\n",
        "    # Want to calculate the avg embedding across all words \n",
        "    # This is the max_sent_len dimension so dim=1\n",
        "    total_emb = torch.sum(embedded, dim=1)\n",
        "\n",
        "    # Count number of non-zero embeddings to average over\n",
        "    non_zero_embs = torch.sum(embedded != 0, dim=[1])\n",
        "    avg_emb = total_emb / non_zero_embs\n",
        "\n",
        "    return avg_emb\n",
        "\n",
        "  def forward(self, x):\n",
        "    # x has shape (batch_size, max_sent_len)\n",
        "    embedded = self.embedding(x)\n",
        "    \n",
        "    # embedding has shape (batch_size, max_sent_len, embedding_dim)\n",
        "    # Compute the average embeddings of shape (batch_size, embedding_dim) \n",
        "    averaged = self.average_embedding(embedded)\n",
        "\n",
        "    # TODO: extra features\n",
        "\n",
        "    out = self.fc1(averaged)\n",
        "    out = self.relu1(out)\n",
        "    out = self.fc2(out)\n",
        "    return out"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LHUOYthCIdjL"
      },
      "source": [
        "def get_word2idx(tokenized_corpus):\n",
        "  vocabulary = []\n",
        "  for sentence in tokenized_corpus:\n",
        "    for token in sentence:\n",
        "      if token not in vocabulary:\n",
        "        vocabulary.append(token)\n",
        "  word2idx = {w: idx+1 for (idx, w) in enumerate(vocabulary)}\n",
        "  word2idx['<pad>'] = 0\n",
        "  return word2idx\n",
        "\n",
        "def get_model_inputs(tokenized_corpus, word2idx, labels):\n",
        "  # we index our sentences\n",
        "  vectorized_sents = [[word2idx[tok] for tok in sent if tok in word2idx] for sent in tokenized_corpus]\n",
        "\n",
        "  # Sentence lengths\n",
        "  sent_lengths = [len(sent) for sent in vectorized_sents]\n",
        "\n",
        "  # Get maximum length\n",
        "  max_len = max(sent_lengths)\n",
        "  \n",
        "  # we create a tensor of a fixed size filled with zeroes for padding\n",
        "  sent_tensor = torch.zeros((len(vectorized_sents), max_len)).long()\n",
        "\n",
        "  # we fill it with our vectorized sentences \n",
        "  for idx, (sent, sentlen) in enumerate(zip(vectorized_sents, sent_lengths)):\n",
        "    sent_tensor[idx, :sentlen] = torch.LongTensor(sent)\n",
        "\n",
        "  # Label tensor\n",
        "  label_tensor = torch.FloatTensor(labels)\n",
        "  \n",
        "  return sent_tensor, label_tensor\n",
        "\n",
        "# tokenized_corpus = get_tokenized_corpus(train)\n",
        "word2idx = get_word2idx(tokenized_corpus)\n",
        "train_sent_tensor, train_label_tensor = get_model_inputs(tokenized_corpus, word2idx, train_labels)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RdACKBTMHHxb",
        "outputId": "b56efa6a-a383-4e56-a928-2ae4136e4a72",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 555
        }
      },
      "source": [
        "EPOCHS = 10\n",
        "LRATE = 0.5\n",
        "EMBEDDING_DIM = 10 # ~4th root of vocab size\n",
        "HIDDEN_DIM = 50\n",
        "OUTPUT_DIM = 1\n",
        "\n",
        "# Construct the model\n",
        "model = FFNN(EMBEDDING_DIM, HIDDEN_DIM, len(word2idx), OUTPUT_DIM)\n",
        "print(model)\n",
        "\n",
        "# we use the stochastic gradient descent (SGD) optimizer\n",
        "optimizer = optim.SGD(model.parameters(), lr=LRATE)\n",
        "\n",
        "# we use the binary cross-entropy loss with sigmoid (applied to logits) \n",
        "# Recall that we did not apply any activation to our output layer, hence we need\n",
        "# to make our outputs look like probabilities.\n",
        "loss_fn = nn.BCEWithLogitsLoss()\n",
        "\n",
        "# Input and label tensors\n",
        "feature = train_sent_tensor\n",
        "target = train_label_tensor\n",
        "\n",
        "#print(train_dataset[:5])\n",
        "#print(dev_dataset[:5])\n",
        "\n",
        "# Start training\n",
        "for epoch in tqdm(range(1, EPOCHS + 1)):\n",
        "  # to ensure the dropout (explained later) is \"turned on\" while training\n",
        "  # good practice to include even if do not use here\n",
        "  model.train()\n",
        "  \n",
        "  # we zero the gradients as they are not removed automatically\n",
        "  optimizer.zero_grad()\n",
        "  \n",
        "  # squeeze is needed as the predictions will have the shape (batch size, 1)\n",
        "  # and we need to remove the dimension of size 1\n",
        "  predictions = model(feature).squeeze(1)\n",
        "\n",
        "  # Compute the loss\n",
        "  loss = loss_fn(predictions, target)\n",
        "  train_loss = loss.item()\n",
        "\n",
        "  # calculate the gradient of each parameter\n",
        "  loss.backward()\n",
        "\n",
        "  # update the parameters using the gradients and optimizer algorithm \n",
        "  optimizer.step()\n",
        "  \n",
        "  print(f'| Epoch: {epoch:02} | Train Loss: {train_loss:.3f}')"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/10 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "FFNN(\n",
            "  (embedding): Embedding(9951, 10, padding_idx=0)\n",
            "  (fc1): Linear(in_features=10, out_features=50, bias=True)\n",
            "  (relu1): ReLU()\n",
            "  (fc2): Linear(in_features=50, out_features=1, bias=True)\n",
            ")\n",
            "4049    Hawaii judge rejects Trump administration requ...\n",
            "2272     <Read/> the full text of Trump 's infrastruct...\n",
            "731     Michigan <woman/> held captive , sexually assa...\n",
            "870      <Autopsies/> of victims show chemical weapons...\n",
            "7489    Disappearing Seagrass Protects Against <Pathog...\n",
            "Name: original, dtype: object\n",
            "2821    Bitcoin just tanked below $ 10,000 after SEC s...\n",
            "2789    Iraqi <forces/> capture 5 top IS leaders in cr...\n",
            "7243    Why African millennials ca n't <get/> enough o...\n",
            "4524    Hungary : Protesters rally in defense of <univ...\n",
            "6372    Kushner , CIM to Get $ 600 Million JPMorgan Lo...\n",
            "Name: original, dtype: object\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-37c1b3b32355>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m   \u001b[0;31m# squeeze is needed as the predictions will have the shape (batch size, 1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m   \u001b[0;31m# and we need to remove the dimension of size 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m   \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m   \u001b[0;31m# Compute the loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'feature' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2CvKSNGLLPO",
        "outputId": "4606d63f-f7f9-4276-c070-ccdb7befb757",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        }
      },
      "source": [
        "import collections\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
        "\n",
        "count_vec = CountVectorizer()\n",
        "count_occurs = count_vec.fit_transform([doc])\n",
        "count_occur_df = pd.DataFrame((count, word) for word, count in zip(count_occurs.toarray().tolist()[0], count_vec.get_feature_names()))\n",
        "count_occur_df.columns = ['Word', 'Count']\n",
        "count_occur_df.sort_values('Count', ascending=False, inplace=True)\n",
        "count_occur_df.head()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-2aeb1e72a3a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mcount_vec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mcount_occurs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcount_vec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mcount_occur_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcount_occurs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount_vec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mcount_occur_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'Word'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Count'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m         vocabulary, X = self._count_vocab(raw_documents,\n\u001b[0;32m-> 1220\u001b[0;31m                                           self.fixed_vocabulary_)\n\u001b[0m\u001b[1;32m   1221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1222\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m   1129\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mraw_documents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m             \u001b[0mfeature_counter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1131\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0manalyze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1132\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1133\u001b[0m                     \u001b[0mfeature_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_analyze\u001b[0;34m(doc, analyzer, tokenizer, ngrams, preprocessor, decoder, stop_words)\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpreprocessor\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m             \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_preprocess\u001b[0;34m(doc, accent_function, lower)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \"\"\"\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlower\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maccent_function\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccent_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'spacy.tokens.doc.Doc' object has no attribute 'lower'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rdeFaoc3lDpK"
      },
      "source": [
        "###  No pre-trained representations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "46gm47T4lDpQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfc49d64-356e-4ec0-ac91-46e031aea2fb"
      },
      "source": [
        "# TODO:\n",
        "# - remove stop words\n",
        "# - different norms\n",
        "# - pre: weigh query terms higher for certain\n",
        "\n",
        "train_and_dev = train_df['edit']\n",
        "\n",
        "training_data, dev_data, training_y, dev_y = train_test_split(train_df['edit'], train_df['meanGrade'],\n",
        "                                                                        test_size=(1-train_proportion),\n",
        "                                                                        random_state=42)\n",
        "\n",
        "# We train a Tf-idf model\n",
        "count_vect = CountVectorizer(stop_words='english')\n",
        "train_counts = count_vect.fit_transform(training_data)\n",
        "transformer = TfidfTransformer().fit(train_counts)\n",
        "train_counts = transformer.transform(train_counts)\n",
        "regression_model = LinearRegression().fit(train_counts, training_y)\n",
        "\n",
        "# Train predictions\n",
        "predicted_train = regression_model.predict(train_counts)\n",
        "\n",
        "# Calculate Tf-idf using train and dev, and validate model on dev:\n",
        "test_and_test_counts = count_vect.transform(train_and_dev)\n",
        "transformer = TfidfTransformer().fit(test_and_test_counts)\n",
        "\n",
        "test_counts = count_vect.transform(dev_data)\n",
        "\n",
        "test_counts = transformer.transform(test_counts)\n",
        "\n",
        "# Dev predictions\n",
        "predicted = regression_model.predict(test_counts)\n",
        "\n",
        "# We run the evaluation:\n",
        "print(\"\\nTrain performance:\")\n",
        "sse, mse = model_performance(predicted_train, training_y, True)\n",
        "\n",
        "print(\"\\nDev performance:\")\n",
        "sse, mse = model_performance(predicted, dev_y, True)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Train performance:\n",
            "| MSE: 0.13 | RMSE: 0.37 |\n",
            "\n",
            "Dev performance:\n",
            "| MSE: 0.36 | RMSE: 0.60 |\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9HyHwHkUlDpa"
      },
      "source": [
        "#### Baseline for task 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7DA3q4o1lDpd",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "#Â Baseline for the task\n",
        "pred_baseline = torch.zeros(len(dev_y)) + np.mean(training_y)\n",
        "print(\"\\nBaseline performance:\")\n",
        "sse, mse = model_performance(pred_baseline, dev_y, True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GhxU3EJ8vDFe"
      },
      "source": [
        "### Neural Net Classifier Approach\n",
        "# TODO: need to split this up and use the existing bits we have"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TmWVpk7yvHHZ",
        "outputId": "6d085543-cc15-4843-c967-9176d288800e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, random_split\n",
        "import nltk\n",
        "import torch.optim as optim\n",
        "from tqdm import tqdm\n",
        "import re\n",
        "import pandas as pd\n",
        "import spacy\n",
        "\n",
        "!python3 -m spacy download en_core_web_sm\n",
        "ner = spacy.load(\"en_core_web_sm\")\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Load data\n",
        "train_df = pd.read_csv('train.csv')\n",
        "test_df = pd.read_csv('dev.csv')\n",
        "train_proportion = 0.8\n",
        "\n",
        "class Task1DatasetNN(Dataset):\n",
        "\n",
        "  def __init__(self, train_data, labels, max_len, word2idx, entity2idx, stopwords=nltk.corpus.stopwords.words('english')):\n",
        "    self.x_train = train_data\n",
        "    self.y_train = labels\n",
        "    self.stopwords = stopwords\n",
        "    self.max_len = max_len\n",
        "    self.word2idx = word2idx\n",
        "    self.entity2idx = entity2idx\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.y_train)\n",
        "\n",
        "  def __getitem__(self, item):\n",
        "    headline = self.x_train[item]\n",
        "\n",
        "    # Remove punctuation\n",
        "    headline = re.sub(r'[^\\w\\s]', '', headline)\n",
        "\n",
        "    # Map headlines to list of entity IDs\n",
        "    # entities = [self.entity2idx[str(e)] for e in ner(headline).ents if str(e) in self.entity2idx]\n",
        "\n",
        "    # Tokenize, lowercase, remove stop words\n",
        "    headline = [w.lower() for w in headline.split() if w not in self.stopwords and len(w)]\n",
        "\n",
        "    # Get headline vector\n",
        "    vectorized_headline = [self.word2idx[tok] for tok in headline if tok in self.word2idx]\n",
        "    headline_tensor = torch.zeros((self.max_len,)).long()\n",
        "    headline_tensor[:len(vectorized_headline)] = torch.LongTensor(vectorized_headline)\n",
        "\n",
        "    target_tensor = torch.FloatTensor([self.y_train[item]])\n",
        "    extra_features = []\n",
        "\n",
        "    return {\n",
        "      'encoding': headline_tensor,\n",
        "      'extra_features': torch.tensor(extra_features),\n",
        "      'target': target_tensor\n",
        "    }\n",
        "\n",
        "#%%\n",
        "\n",
        "TOKEN_PATTERN = re.compile(\"\\w+\")\n",
        "def tokenize(sentence):\n",
        "  return TOKEN_PATTERN.findall(sentence)\n",
        "\n",
        "# Remove angle brackets and lowercase\n",
        "def preprocess(word):\n",
        "  if len(word) > 2 and word[0] == '<' and word[-2] == '/' and word[-1] == '>' :\n",
        "    word = word[1:-2]\n",
        "  return word.lower()\n",
        "\n",
        "# Create vocab of all words\n",
        "def create_vocab(data):\n",
        "  # Let us put the tokenized corpus in a list\n",
        "  tokenized_corpus = [[preprocess(t) for t in tokenize(s)] for s in data]\n",
        "\n",
        "  # Create single list of all vocabulary\n",
        "  vocabulary = []\n",
        "  for sentence in tokenized_corpus:\n",
        "    for token in sentence:\n",
        "      if token not in vocabulary:\n",
        "        vocabulary.append(token)\n",
        "\n",
        "  return vocabulary, tokenized_corpus\n",
        "\n",
        "# TODO: need to tie this in with NER\n",
        "def build_word2idx(tokenized_corpus):\n",
        "  vocabulary = []\n",
        "  for sentence in tokenized_corpus:\n",
        "    for token in sentence:\n",
        "      if token not in vocabulary:\n",
        "        vocabulary.append(token)\n",
        "  w2i = {w: idx+1 for (idx, w) in enumerate(vocabulary)}\n",
        "  w2i['<pad>'] = 0\n",
        "  return w2i\n",
        "\n",
        "# Get NER lookup table from training data\n",
        "def build_entity2idx(corpus):\n",
        "  entities = {}\n",
        "  idx = 0\n",
        "  for s in corpus:\n",
        "    doc = ner(s)\n",
        "    for e in doc.ents:\n",
        "      e = str(e)\n",
        "      if e not in entities:\n",
        "        entities[e] = idx\n",
        "        idx+=1\n",
        "  return entities\n",
        "\n",
        "#%%\n",
        "\n",
        "# e2i = get_entity2idx(corpus)\n",
        "# print(e2i)\n",
        "# print(type(e2i['Trump']))\n",
        "# efs = get_entity_features(corpus, e2i)\n",
        "# print(efs[:10])\n",
        "\n",
        "#%%\n",
        "\n",
        "class FFNN(nn.Module):\n",
        "  def __init__(self, embedding_dim, hidden_dim, vocab_size, num_classes):\n",
        "    super(FFNN, self).__init__()\n",
        "    self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
        "    self.fc1 = nn.Linear(embedding_dim, hidden_dim)\n",
        "    self.relu1 = nn.ReLU()\n",
        "    self.fc2 = nn.Linear(hidden_dim, num_classes)\n",
        "    self.relu2 = nn.ReLU()\n",
        "\n",
        "  # Average sentence embedding (ignoring padding)\n",
        "  # Maps embedded : (batch_size, max_sent_len, embedding_dim) => (batch_size, embeddind_dim)\n",
        "  def average_embedding(self, embedded):\n",
        "    # Want to calculate the avg embedding across all words\n",
        "    # This is the max_sent_len dimension so dim=1\n",
        "    total_emb = torch.sum(embedded, dim=1)\n",
        "\n",
        "    # Count number of non-zero embeddings to average over\n",
        "    non_zero_embs = torch.sum(embedded != 0, dim=[1])\n",
        "    avg_emb = total_emb / non_zero_embs\n",
        "\n",
        "    return avg_emb\n",
        "\n",
        "  def forward(self, x):\n",
        "    # x has shape (batch_size, max_sent_len)\n",
        "    embedded = self.embedding(x)\n",
        "\n",
        "    # embedding has shape (batch_size, max_sent_len, embedding_dim)\n",
        "    # Compute the average embeddings of shape (batch_size, embedding_dim)\n",
        "    averaged = self.average_embedding(embedded)\n",
        "\n",
        "    # TODO: extra features\n",
        "\n",
        "    out = self.fc1(averaged)\n",
        "    out = self.relu1(out)\n",
        "    out = self.fc2(out)\n",
        "    # out = self.relu2(out)\n",
        "    return out\n",
        "\n",
        "\n",
        "#%%\n",
        "\n",
        "EPOCHS = 10\n",
        "LRATE = 0.1\n",
        "EMBEDDING_DIM = 20 # ~4th root of vocab size\n",
        "HIDDEN_DIM = 50\n",
        "OUTPUT_DIM = 1\n",
        "\n",
        "# Set training and test data\n",
        "training_data = train_df['original']\n",
        "training_labels = train_df['meanGrade']\n",
        "test_data = test_df['original']\n",
        "\n",
        "_vocab, tokenized_corpus = create_vocab(training_data)\n",
        "max_headline_len = max([len([w for w in s.split()]) for s in training_data])\n",
        "w2i = build_word2idx(tokenized_corpus)\n",
        "# e2i = build_entity2idx(training_data)\n",
        "e2i = {}\n",
        "\n",
        "train_and_dev = Task1DatasetNN(training_data, training_labels, max_headline_len, w2i, e2i)\n",
        "\n",
        "# TODO: what processing should be done on both train and dev and what should be done on just train???\n",
        "# Split training data into train and dev sets\n",
        "train_examples = round(len(training_data)*train_proportion)\n",
        "dev_examples = len(training_data) - train_examples\n",
        "train_dataset, dev_dataset = random_split(train_and_dev, (train_examples, dev_examples))\n",
        "\n",
        "# train_sent_tensor, train_label_tensor\n",
        "i2w = {v:k for k,v in w2i.items()}\n",
        "\n",
        "# for a, d in zip(training_data, train_and_dev):\n",
        "#   d = d['encoding'].tolist()\n",
        "#   dec = [i2w[i] for i in d]\n",
        "#   print(a)\n",
        "#   print(dec)\n",
        "\n",
        "\n",
        "#%%\n",
        "\n",
        "# Create data loaders\n",
        "BATCH_SIZE = 50\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, shuffle=True, batch_size=BATCH_SIZE)\n",
        "dev_loader = torch.utils.data.DataLoader(dev_dataset, batch_size=BATCH_SIZE)\n",
        "\n",
        "# Construct the model\n",
        "model = FFNN(EMBEDDING_DIM, HIDDEN_DIM, len(w2i), OUTPUT_DIM)\n",
        "print(model)\n",
        "\n",
        "# we use the stochastic gradient descent (SGD) optimizer\n",
        "optimizer = optim.SGD(model.parameters(), lr=LRATE)\n",
        "\n",
        "# we use the binary cross-entropy loss with sigmoid (applied to logits)\n",
        "# Recall that we did not apply any activation to our output layer, hence we need\n",
        "# to make our outputs look like probabilities.\n",
        "loss_fn = nn.MSELoss()\n",
        "\n",
        "# Start training\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "EPOCHS = 10\n",
        "for epoch in range(EPOCHS):\n",
        "  # to ensure the dropout (explained later) is \"turned on\" while training\n",
        "  # good practice to include even if do not use here\n",
        "  model.train()\n",
        "\n",
        "  for batch in train_loader:\n",
        "\n",
        "    encoding = batch['encoding'].to(device)\n",
        "    target = batch['target'].to(device).squeeze(1)\n",
        "    # extra_features = batch['extra_features'].to(device)\n",
        "\n",
        "    # we zero the gradients as they are not removed automatically\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # squeeze is needed as the predictions will have the shape (batch size, 1)\n",
        "    # and we need to remove the dimension of size 1\n",
        "    predictions = model(encoding).squeeze(1)\n",
        "\n",
        "    # Compute the loss\n",
        "    loss = loss_fn(predictions, target)\n",
        "    train_loss = loss.item()\n",
        "\n",
        "    # calculate the gradient of each parameter\n",
        "    loss.backward()\n",
        "\n",
        "    # update the parameters using the gradients and optimizer algorithm\n",
        "    optimizer.step()\n",
        "\n",
        "  print(f'| Epoch: {epoch:02} | Train Loss: {train_loss:.3f}')\n",
        "#%%"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in /usr/local/lib/python3.7/dist-packages (2.2.5)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.19.5)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.5)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.8.2)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (53.0.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.5)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.7.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.4.0)\n",
            "\u001b[38;5;2mâœ” Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "FFNN(\n",
            "  (embedding): Embedding(7265, 20, padding_idx=0)\n",
            "  (fc1): Linear(in_features=20, out_features=50, bias=True)\n",
            "  (relu1): ReLU()\n",
            "  (fc2): Linear(in_features=50, out_features=1, bias=True)\n",
            "  (relu2): ReLU()\n",
            ")\n",
            "| Epoch: 00 | Train Loss: 0.278\n",
            "| Epoch: 01 | Train Loss: 0.342\n",
            "| Epoch: 02 | Train Loss: 0.326\n",
            "| Epoch: 03 | Train Loss: 0.467\n",
            "| Epoch: 04 | Train Loss: 0.282\n",
            "| Epoch: 05 | Train Loss: 0.299\n",
            "| Epoch: 06 | Train Loss: 0.481\n",
            "| Epoch: 07 | Train Loss: 0.469\n",
            "| Epoch: 08 | Train Loss: 0.358\n",
            "| Epoch: 09 | Train Loss: 0.226\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}