{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "task_1_main.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "22dbae44b2c343d883c81b5e871e4ea8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_210ed54832414e818ffb07ae69e003c3",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3597bce8eeb147e7b876e3f6f31ec294",
              "IPY_MODEL_ca4413e8f3464acface7a3dd8fdbd9bf"
            ]
          }
        },
        "210ed54832414e818ffb07ae69e003c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3597bce8eeb147e7b876e3f6f31ec294": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_5128bbc48adc400ea5112e484dbb4079",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2c815a87db614ac7baa8117410ec851d"
          }
        },
        "ca4413e8f3464acface7a3dd8fdbd9bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2c8691af7dc040c6afdd6ddaf1a66a6f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 3.26MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7974f04bdb564c4590604c8383503a98"
          }
        },
        "5128bbc48adc400ea5112e484dbb4079": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2c815a87db614ac7baa8117410ec851d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2c8691af7dc040c6afdd6ddaf1a66a6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7974f04bdb564c4590604c8383503a98": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5ef54901d4a94072a2d63e754f1b8d2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_11cb7b75946a4a5e815fc431aef733ad",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9de1c43596c04fa380523f98865906fc",
              "IPY_MODEL_41fb10980e1546f6878fcd4567db36f6"
            ]
          }
        },
        "11cb7b75946a4a5e815fc431aef733ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9de1c43596c04fa380523f98865906fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f0e67a73a3ff4035a60b6c01fa769703",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 481,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 481,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9ba2619f2acc4ca6bdb6e38e1c8901b7"
          }
        },
        "41fb10980e1546f6878fcd4567db36f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_19c90cf51d6648398d83a6eb03401c98",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 481/481 [00:09&lt;00:00, 52.2B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_69776ef926444178b3e25f156a47fc72"
          }
        },
        "f0e67a73a3ff4035a60b6c01fa769703": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9ba2619f2acc4ca6bdb6e38e1c8901b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "19c90cf51d6648398d83a6eb03401c98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "69776ef926444178b3e25f156a47fc72": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c999ee24ac8f49568380f9c87b671474": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_fe88f18fa3be4ad29d76ccb0e2b4596c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_85249428c9234f2e9b3282ef88c5f610",
              "IPY_MODEL_63ec78a55df64b32baecec8240279fa0"
            ]
          }
        },
        "fe88f18fa3be4ad29d76ccb0e2b4596c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "85249428c9234f2e9b3282ef88c5f610": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_9f61e8627a034e27a4a543fbd6218a5f",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 501200538,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 501200538,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c919b91a00154087bb666f53e59d9549"
          }
        },
        "63ec78a55df64b32baecec8240279fa0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_344eb188121d43afb1b156873768a459",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 501M/501M [00:08&lt;00:00, 55.8MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_502e2c39ee8e4175a596fb2b56257454"
          }
        },
        "9f61e8627a034e27a4a543fbd6218a5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c919b91a00154087bb666f53e59d9549": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "344eb188121d43afb1b156873768a459": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "502e2c39ee8e4175a596fb2b56257454": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2TvyemfDlDmu"
      },
      "source": [
        "# NLP CW Task 1\n",
        "\n",
        "  - Approach 1, which can use use pre-trained embeddings / models\n",
        "  - Approach 2, which should not use any pre-trained embeddings or models\n",
        "\n",
        "#### Running your code:\n",
        "  - Your models should run automatically when running your colab file without further intervention\n",
        "  - For each task you should automatically output the performance of both models\n",
        "  - Your code should automatically download any libraries required\n",
        "\n",
        "#### Structure of your code:\n",
        "  - You are expected to use the 'train', 'eval' and 'model_performance' functions, although you may edit these as required\n",
        "  - Otherwise there are no restrictions on what you can do in your code\n",
        "\n",
        "#### Documentation:\n",
        "  - You are expected to produce a .README file summarising how you have approached both tasks\n",
        "  - Your .README file should explain how to replicate the different experiments mentioned in your report"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LRWFk-kelDoA"
      },
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, random_split\n",
        "from collections import Counter\n",
        "import nltk\n",
        "import string\n",
        "import torchtext\n",
        "import torch.optim as optim\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import binned_statistic\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "import codecs\n",
        "import tqdm\n",
        "import re"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "lJCEYZNOleKm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa3bfe3a-7641-478b-a5af-be556bf054fc"
      },
      "source": [
        "# Get pretrained GloVe embeddings\n",
        "glove = torchtext.vocab.GloVe(name='6B', dim=50)\n",
        "\n",
        "# Install packages that Colab does not provide automatically\n",
        "!pip -q install transformers\n",
        "from transformers import RobertaTokenizer, RobertaModel, BertPreTrainedModel, DistilBertModel, DistilBertTokenizer\n",
        "\n",
        "# Download stopwords\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Get test and train data files\n",
        "if not os.path.exists('dev.csv'):\n",
        "  !wget -q --show-progress https://raw.githubusercontent.com/matt-malarkey/nlp-cw-data/master/dev.csv\n",
        "  !wget -q --show-progress https://raw.githubusercontent.com/matt-malarkey/nlp-cw-data/master/train.csv\n",
        "\n",
        "if not os.path.exists('competition_test.csv'):\n",
        "  !wget -q --show-progress https://raw.githubusercontent.com/matt-malarkey/nlp-cw-data/master/competition_test.csv"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X09jt8VRlDoM"
      },
      "source": [
        "# Setting random seed and device\n",
        "SEED = 1\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AqhlzLl6lDoO"
      },
      "source": [
        "# Load data\n",
        "train_df = pd.read_csv('train.csv')\n",
        "test_df = pd.read_csv('dev.csv')\n",
        "comp_test_df = pd.read_csv('competition_test.csv')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3RCmF7xulDoP"
      },
      "source": [
        "# Number of epochs\n",
        "epochs = 10\n",
        "\n",
        "# Proportion of training data for train compared to dev\n",
        "train_proportion = 0.8"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qAgZW6K1lDoR"
      },
      "source": [
        "# We define our training loop\n",
        "def train(train_iter, dev_iter, model, number_epoch, optimizer):\n",
        "  \"\"\"\n",
        "  Training loop for the model, which calls on eval to evaluate after each epoch\n",
        "  \"\"\"\n",
        "\n",
        "  print(\"Training model.\")\n",
        "\n",
        "  loss_fn = nn.MSELoss()\n",
        "  loss_fn = loss_fn.to(device)\n",
        "\n",
        "  performance_stats = []\n",
        "\n",
        "  for epoch in range(1, number_epoch+1):\n",
        "    model.train()\n",
        "\n",
        "    epoch_loss = 0\n",
        "    epoch_sse = 0\n",
        "    no_observations = 0  # Observations used for training so far\n",
        "\n",
        "    for batch in train_iter:\n",
        "      ids = batch['ids'].to(device).squeeze()\n",
        "      mask = batch['mask'].to(device).squeeze()\n",
        "      target = batch['target'].to(device, dtype=torch.float)\n",
        "      extra_features = batch['extra_features'].to(device)\n",
        "\n",
        "      predictions = model(ids, mask, extra_features).squeeze(1)\n",
        "      optimizer.zero_grad()\n",
        "      loss = loss_fn(predictions, target)\n",
        "\n",
        "      no_observations = no_observations + target.shape[0]\n",
        "      sse, __ = model_performance(predictions.detach().cpu().numpy(), target.detach().cpu().numpy())\n",
        "\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      epoch_loss += loss.item()*target.shape[0]\n",
        "      epoch_sse += sse\n",
        "\n",
        "    valid_loss, valid_mse, __, __ = eval(dev_iter, model)\n",
        "\n",
        "    epoch_loss, epoch_mse = epoch_loss / no_observations, epoch_sse / no_observations\n",
        "    performance_stats.append((valid_loss, valid_mse**0.5))\n",
        "    print(f'| Epoch: {epoch:02} | Train Loss: {epoch_loss:.2f} | Train MSE: {epoch_mse:.2f} | Train RMSE: {epoch_mse**0.5:.2f} | \\\n",
        "    Val. Loss: {valid_loss:.2f} | Val. MSE: {valid_mse:.2f} |  Val. RMSE: {valid_mse**0.5:.2f} |')\n",
        "\n",
        "  return performance_stats"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NzXeDgHmlDob"
      },
      "source": [
        "# We evaluate performance on our dev set\n",
        "def eval(data_iter, model):\n",
        "  \"\"\"\n",
        "  Evaluating model performance on the dev set\n",
        "  \"\"\"\n",
        "  model.eval()\n",
        "  epoch_loss = 0\n",
        "  epoch_sse = 0\n",
        "  pred_all = []\n",
        "  trg_all = []\n",
        "  no_observations = 0\n",
        "  loss_fn = nn.MSELoss()\n",
        "  loss_fn = loss_fn.to(device)\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for batch in data_iter:\n",
        "      ids = batch['ids'].to(device).squeeze()\n",
        "      mask = batch['mask'].to(device).squeeze()\n",
        "      target = batch['target'].to(device, dtype=torch.float)\n",
        "      extra_features = batch['extra_features'].to(device)\n",
        "\n",
        "      predictions = model(ids, mask, extra_features).squeeze(1)\n",
        "\n",
        "      loss = loss_fn(predictions, target)\n",
        "\n",
        "      # We get the mse\n",
        "      pred, trg = predictions.detach().cpu().numpy(), target.detach().cpu().numpy()\n",
        "      sse, __ = model_performance(pred, trg)\n",
        "\n",
        "      no_observations = no_observations + target.shape[0]\n",
        "      epoch_loss += loss.item()*target.shape[0]\n",
        "      epoch_sse += sse\n",
        "      pred_all.extend(pred)\n",
        "      trg_all.extend(trg)\n",
        "\n",
        "  return epoch_loss/no_observations, epoch_sse/no_observations, np.array(pred_all), np.array(trg_all)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_22fHHElDog"
      },
      "source": [
        "# How we print the model performance\n",
        "def model_performance(output, target, print_output=False):\n",
        "  \"\"\"\n",
        "  Returns SSE and MSE per batch (printing the MSE and the RMSE)\n",
        "  \"\"\"\n",
        "  sq_error = (output - target)**2\n",
        "\n",
        "  sse = np.sum(sq_error)\n",
        "  mse = np.mean(sq_error)\n",
        "  rmse = np.sqrt(mse)\n",
        "\n",
        "  if print_output:\n",
        "    print(f'| MSE: {mse:.2f} | RMSE: {rmse:.2f} |')\n",
        "\n",
        "  return sse, mse"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jyew1QfTSuzM"
      },
      "source": [
        "# Data Analysis\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FhhQ12OmSzD6"
      },
      "source": [
        "# Basic Stats\r\n",
        "num_headlines = len(train_df)\r\n",
        "max_len = max(train_df['original'].apply(len))\r\n",
        "avg_score = train_df['meanGrade'].mean()\r\n",
        "print(f'Number of Headlines: {num_headlines}, Max Headline Length: {max_len}, Avg Score: {avg_score:.2f}')\r\n",
        "\r\n",
        "# Most common words\r\n",
        "stopwords = nltk.corpus.stopwords.words('english')\r\n",
        "most_common_words = Counter(\" \".join(train_df['original']).split()).most_common(100)\r\n",
        "stopwords.append(string.punctuation)\r\n",
        "most_common_words = [(word, count) for (word, count) in most_common_words if word not in stopwords and word.isalpha()][:5]\r\n",
        "print(f'Most common words: {most_common_words}')\r\n",
        "\r\n",
        "# Analysis of Trump Headlines\r\n",
        "trump_headlines = train_df[train_df['original'].str.lower().str.contains('trump')]\r\n",
        "num_headlines_with_trump = len(trump_headlines)\r\n",
        "trump_avg_score = trump_headlines['meanGrade'].mean()\r\n",
        "prob_headline_contains_trump = num_headlines_with_trump / num_headlines\r\n",
        "trump_value_counts = trump_headlines['meanGrade'].value_counts(bins=3)\r\n",
        "trump_proportion_gt_one = (trump_value_counts[2] + trump_value_counts[3]) * 100 / num_headlines_with_trump\r\n",
        "print(f'Headlines with Trump: {prob_headline_contains_trump * 100:.2f}%, Avg Score: {trump_avg_score:.2f}')\r\n",
        "print(f'Proportion of Trump Headlines with score > 1: {trump_proportion_gt_one:.2f}%')\r\n",
        "\r\n",
        "# Analysis of word similarity and length of headlines\r\n",
        "semantic_similarity_data = []\r\n",
        "sentence_similarity_data = []\r\n",
        "levenshtein_similarity_data = []\r\n",
        "headline_length_data = []\r\n",
        "\r\n",
        "for row in train_df.itertuples():\r\n",
        "  all_words = row.original.split(' ')\r\n",
        "  headline_length_data.append((len(all_words), row.meanGrade))\r\n",
        "  sentence_vec = torch.zeros((1,50))\r\n",
        "  for i, word in enumerate(all_words):\r\n",
        "    if len(word) > 2 and word[0] == '<' and word[-2] == '/' and word[-1] == '>' :\r\n",
        "      word = word[1:-2].lower()\r\n",
        "      original_word_vec = glove[word].unsqueeze(0)\r\n",
        "      edited_word_vec = glove[row.edit.lower()].unsqueeze(0)\r\n",
        "      semantic_distance = torch.cosine_similarity(original_word_vec, edited_word_vec).item() \r\n",
        "      levenshtein_distance = nltk.edit_distance(word, row.edit.lower())\r\n",
        "      semantic_similarity_data.append((semantic_distance, row.meanGrade))\r\n",
        "      levenshtein_similarity_data.append((levenshtein_distance, row.meanGrade))\r\n",
        "    else:\r\n",
        "      sentence_vec += glove[word.lower()].unsqueeze(0)\r\n",
        "    \r\n",
        "    if i == len(all_words) - 1:\r\n",
        "      sentence_semantic_distance = torch.cosine_similarity(sentence_vec, edited_word_vec)\r\n",
        "      sentence_similarity_data.append((sentence_semantic_distance, row.meanGrade))\r\n",
        "\r\n",
        "\r\n",
        "# Analysis of # of clause separators\r\n",
        "separators_data = []\r\n",
        "for i in range(len(train_df['original'])):\r\n",
        "  matches = re.findall(\"[;,:(...)]\", train_df['original'][i])\r\n",
        "  separators_data.append((len(matches), train_df['meanGrade'][i]))\r\n",
        "\r\n",
        "# Plot word similarity vs meanGrade\r\n",
        "plt.figure(figsize=(15, 10))\r\n",
        "plt.subplot(2, 3, 1)\r\n",
        "mean_stat_similarity = binned_statistic(*zip(*semantic_similarity_data), bins=6, range=(-0.5, 1.0))\r\n",
        "plt.plot(mean_stat_similarity.bin_edges[:-1] + 0.125, mean_stat_similarity.statistic)\r\n",
        "plt.xlabel('Cosine Distance')\r\n",
        "plt.ylabel('Avg Score')\r\n",
        "plt.title('Semantic similarity vs meanGrade')\r\n",
        "\r\n",
        "# Levenshtein distance vs meanGrade\r\n",
        "plt.subplot(2, 3, 2)\r\n",
        "mean_stat_similarity = binned_statistic(*zip(*levenshtein_similarity_data), bins=6)\r\n",
        "plt.plot(mean_stat_similarity.bin_edges[:-1] + 0.125, mean_stat_similarity.statistic)\r\n",
        "plt.xlabel('Levenshtein Distance')\r\n",
        "plt.ylabel('Avg Score')\r\n",
        "plt.title('Word spelling similarity vs meanGrade')\r\n",
        "\r\n",
        "# Semantic similarity of word to headline vs meanGrade\r\n",
        "plt.subplot(2, 3, 3)\r\n",
        "mean_stat_similarity = binned_statistic(*zip(*sentence_similarity_data), bins=6)\r\n",
        "plt.plot(mean_stat_similarity.bin_edges[:-1] + 0.125, mean_stat_similarity.statistic)\r\n",
        "plt.xlabel('Cosine Distance')\r\n",
        "plt.ylabel('Avg Score')\r\n",
        "plt.title('Semantic similarity of word to headline vs meanGrade')\r\n",
        "\r\n",
        "# Plot clause separator count vs meanGrade\r\n",
        "plt.subplot(2, 3, 4)\r\n",
        "plt.plot()\r\n",
        "mean_stat_seps = binned_statistic(*zip(*separators_data), bins=6)\r\n",
        "plt.plot(mean_stat_seps.bin_edges[:-1], mean_stat_seps.statistic)\r\n",
        "plt.xlabel('Number of Clause Separators')\r\n",
        "plt.ylabel('Avg Score')\r\n",
        "plt.title('Clause Separator Count vs meanGrade')\r\n",
        "\r\n",
        "# Plot headline length vs meanGrade\r\n",
        "plt.subplot(2, 3, 5)\r\n",
        "mean_stat_headline_len = binned_statistic(*zip(*headline_length_data), bins=30, range=(0, 30))\r\n",
        "plt.plot(mean_stat_headline_len.bin_edges[:-1], mean_stat_headline_len.statistic)\r\n",
        "plt.xlabel('Number of Words')\r\n",
        "plt.ylabel('Avg Score')\r\n",
        "plt.title('Headline Length vs meanGrade')\r\n",
        "\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "cenE48y9leKo"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "2spyhNrBleKo"
      },
      "source": [
        "# Pattern to match words and multiword tags\n",
        "# See https://regex101.com/r/a2cWZL/1 for example\n",
        "# TOKEN_PATTERN = re.compile(\"[A-Za-z#]+|<[A-Za-z#]+\\s[A-Za-z]+\\/>\")\n",
        "\n",
        "# Patten to match only words\n",
        "TOKEN_PATTERN = re.compile(\"\\w+\")\n",
        "CLAUSE_SEPS = re.compile(\"[;,:(...)]\")\n",
        "\n",
        "# TODO: processing of:\n",
        "# - hashtags,\n",
        "# - words with a \"-\" in between them\n",
        "# - punctuation\n",
        "# - entity names\n",
        "\n",
        "def tokenize(sentence):\n",
        "  return TOKEN_PATTERN.findall(sentence)\n",
        "\n",
        "# Remove angle brackets and lowercase\n",
        "def preprocess(word):\n",
        "  if len(word) > 2 and word[0] == '<' and word[-2] == '/' and word[-1] == '>' :\n",
        "    word = word[1:-2]\n",
        "  return word.lower()\n",
        "\n",
        "def create_vocab(data):\n",
        "  \"\"\"\n",
        "  Creating a corpus of all the tokens used\n",
        "  \"\"\"\n",
        "  # Let us put the tokenized corpus in a list\n",
        "  tokenized_corpus = [[preprocess(t) for t in tokenize(s)] for s in data]\n",
        "\n",
        "  # Create single list of all vocabulary\n",
        "  vocabulary = []\n",
        "  for sentence in tokenized_corpus:\n",
        "    for token in sentence:\n",
        "      if token not in vocabulary:\n",
        "        vocabulary.append(token)\n",
        "\n",
        "  return vocabulary, tokenized_corpus\n",
        "\n",
        "# Extra features:\n",
        "# [0] - binary if 'Trump' in headline\n",
        "# [1] - length of headline          <--- will passing as a feature help bc all headlines are padded?\n",
        "# [3] - number of clause separators: elipsis, commas, colons or semi colons\n",
        "# other features: avg word length?\n",
        "EXTRA_FEATURES = 3\n",
        "def extract_features(raw_headline):\n",
        "  return [\n",
        "    int('Trump' in raw_headline), \n",
        "    len(raw_headline),\n",
        "    len(CLAUSE_SEPS.findall(raw_headline))\n",
        "  ]"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "aoC2hQrNleKp"
      },
      "source": [
        "# Inherits from Dataset class so the DataLoader can use it\n",
        "class Task1Dataset(Dataset):\n",
        "\n",
        "  def __init__(self, tokenizer, train_data, labels):\n",
        "    self.x_train = train_data\n",
        "    self.y_train = labels\n",
        "    self.tokenizer = tokenizer\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.y_train)\n",
        "\n",
        "  def __getitem__(self, item):\n",
        "    # Preprocess headline before embedding\n",
        "    headline = self.x_train[item]\n",
        "    # processed_headline = ' '.join([preprocess(t) for t in tokenize(headline)])\n",
        "    processed_headline = [preprocess(t) for t in tokenize(headline)]\n",
        "\n",
        "    target = self.y_train[item]\n",
        "\n",
        "    # Use is_split_into_words=True to allow for our own tokenizing\n",
        "    # - stops encode_plus splitting up unknown words into multiple parts\n",
        "    encoding = self.tokenizer.encode_plus(processed_headline, return_tensors='pt',\n",
        "                                          padding='max_length', truncation=True,\n",
        "                                          max_length=128, pad_to_max_length=True,\n",
        "                                          is_split_into_words=True)\n",
        "    ids = encoding['input_ids']\n",
        "    mask = encoding['attention_mask']\n",
        "\n",
        "    extra_features = extract_features(headline)\n",
        "\n",
        "    return {\n",
        "      'ids': torch.tensor(ids),\n",
        "      'mask': torch.tensor(mask),\n",
        "      'target': torch.tensor(target),\n",
        "      'extra_features': torch.tensor(extra_features)\n",
        "    }"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sWaxTh2UlDoy"
      },
      "source": [
        "class BertRegressionModel(nn.Module):\n",
        "  def __init__(self, model_name):\n",
        "    super(BertRegressionModel, self).__init__()\n",
        "\n",
        "    if model_name == 'distilbert':\n",
        "      self.bert = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
        "    elif model_name == 'roberta':\n",
        "      self.bert = RobertaModel.from_pretrained('roberta-base')\n",
        "    \n",
        "    self.num_extra_features = EXTRA_FEATURES\n",
        "    self.linear1 = nn.Linear(768, 32)\n",
        "    self.linear2 = nn.Linear(32 + self.num_extra_features, 1)\n",
        "\n",
        "  def forward(self, ids, mask, extra_features):\n",
        "    embeddings = self.bert(input_ids=ids, attention_mask=mask)[0]\n",
        "    x = self.linear1(embeddings[:, 0])\n",
        "    concat_features = torch.cat([x, extra_features], dim=1)\n",
        "    x = self.linear2(concat_features)\n",
        "    return x"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g190qtchuI2W"
      },
      "source": [
        "### Approach 1: Using pre-trained representations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "bp9d32sOlDo6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "22dbae44b2c343d883c81b5e871e4ea8",
            "210ed54832414e818ffb07ae69e003c3",
            "3597bce8eeb147e7b876e3f6f31ec294",
            "ca4413e8f3464acface7a3dd8fdbd9bf",
            "5128bbc48adc400ea5112e484dbb4079",
            "2c815a87db614ac7baa8117410ec851d",
            "2c8691af7dc040c6afdd6ddaf1a66a6f",
            "7974f04bdb564c4590604c8383503a98"
          ]
        },
        "outputId": "e7f71b06-5be8-4cad-cdf5-347dd59cc52e"
      },
      "source": [
        "BATCH_SIZE = 32\n",
        "\n",
        "# Initialise chosen BERT model and tokenizer\n",
        "# To change the model to use Roberta, pass in 'roberta' to the regression model\n",
        "# and uncomment the tokenizer below.\n",
        "model = BertRegressionModel('distilbert').to(device)\n",
        "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "# tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
        "\n",
        "# Set training and test data\n",
        "training_data = train_df['original']\n",
        "training_labels = train_df['meanGrade']\n",
        "test_data = test_df['original']\n",
        "train_and_dev = Task1Dataset(tokenizer, training_data, training_labels)\n",
        "\n",
        "# Split training data into train and dev sets\n",
        "train_examples = round(len(train_and_dev)*train_proportion)\n",
        "dev_examples = len(train_and_dev) - train_examples\n",
        "train_dataset, dev_dataset = random_split(train_and_dev, (train_examples, dev_examples))\n",
        "\n",
        "# Create data loaders\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, shuffle=True, batch_size=BATCH_SIZE)\n",
        "dev_loader = torch.utils.data.DataLoader(dev_dataset, batch_size=BATCH_SIZE)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "22dbae44b2c343d883c81b5e871e4ea8",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descriptiâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wFxhZKMC783t",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 574,
          "referenced_widgets": [
            "5ef54901d4a94072a2d63e754f1b8d2c",
            "11cb7b75946a4a5e815fc431aef733ad",
            "9de1c43596c04fa380523f98865906fc",
            "41fb10980e1546f6878fcd4567db36f6",
            "f0e67a73a3ff4035a60b6c01fa769703",
            "9ba2619f2acc4ca6bdb6e38e1c8901b7",
            "19c90cf51d6648398d83a6eb03401c98",
            "69776ef926444178b3e25f156a47fc72",
            "c999ee24ac8f49568380f9c87b671474",
            "fe88f18fa3be4ad29d76ccb0e2b4596c",
            "85249428c9234f2e9b3282ef88c5f610",
            "63ec78a55df64b32baecec8240279fa0",
            "9f61e8627a034e27a4a543fbd6218a5f",
            "c919b91a00154087bb666f53e59d9549",
            "344eb188121d43afb1b156873768a459",
            "502e2c39ee8e4175a596fb2b56257454"
          ]
        },
        "outputId": "baf854fc-6fce-4280-e044-6a206f09c545"
      },
      "source": [
        "# Do the training\n",
        "distil_model = BertRegressionModel('distilbert').to(device)\n",
        "optimizer_distil = torch.optim.Adam(distil_model.parameters())\n",
        "tokenizer_distil = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "\n",
        "roberta_model = BertRegressionModel('roberta').to(device)\n",
        "optimizer_roberta = torch.optim.Adam(roberta_model.parameters())\n",
        "tokenizer_roberta = RobertaTokenizer.from_pretrained('roberta-base')\n",
        "\n",
        "performance_stats_roberta = train(train_loader, dev_loader, roberta_model, epochs, optimizer_roberta)\n",
        "performance_stats_distil = train(train_loader, dev_loader, distil_model, epochs, optimizer_distil)\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5ef54901d4a94072a2d63e754f1b8d2c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=481.0, style=ProgressStyle(description_â€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c999ee24ac8f49568380f9c87b671474",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=501200538.0, style=ProgressStyle(descriâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Training model.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:32: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "| Epoch: 01 | Train Loss: 5.12 | Train MSE: 5.12 | Train RMSE: 2.26 |     Val. Loss: 1.96 | Val. MSE: 1.96 |  Val. RMSE: 1.40 |\n",
            "| Epoch: 02 | Train Loss: 1.05 | Train MSE: 1.05 | Train RMSE: 1.03 |     Val. Loss: 0.50 | Val. MSE: 0.50 |  Val. RMSE: 0.71 |\n",
            "| Epoch: 03 | Train Loss: 0.43 | Train MSE: 0.43 | Train RMSE: 0.66 |     Val. Loss: 0.39 | Val. MSE: 0.39 |  Val. RMSE: 0.63 |\n",
            "| Epoch: 04 | Train Loss: 0.37 | Train MSE: 0.37 | Train RMSE: 0.61 |     Val. Loss: 0.34 | Val. MSE: 0.34 |  Val. RMSE: 0.59 |\n",
            "| Epoch: 05 | Train Loss: 0.36 | Train MSE: 0.36 | Train RMSE: 0.60 |     Val. Loss: 0.35 | Val. MSE: 0.35 |  Val. RMSE: 0.59 |\n",
            "| Epoch: 06 | Train Loss: 0.36 | Train MSE: 0.36 | Train RMSE: 0.60 |     Val. Loss: 0.35 | Val. MSE: 0.35 |  Val. RMSE: 0.59 |\n",
            "| Epoch: 07 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.60 |     Val. Loss: 0.34 | Val. MSE: 0.34 |  Val. RMSE: 0.58 |\n",
            "| Epoch: 08 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |     Val. Loss: 0.34 | Val. MSE: 0.34 |  Val. RMSE: 0.59 |\n",
            "| Epoch: 09 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.60 |     Val. Loss: 0.33 | Val. MSE: 0.33 |  Val. RMSE: 0.57 |\n",
            "| Epoch: 10 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |     Val. Loss: 0.33 | Val. MSE: 0.33 |  Val. RMSE: 0.57 |\n",
            "Training model.\n",
            "| Epoch: 01 | Train Loss: 0.66 | Train MSE: 0.66 | Train RMSE: 0.81 |     Val. Loss: 0.35 | Val. MSE: 0.35 |  Val. RMSE: 0.59 |\n",
            "| Epoch: 02 | Train Loss: 0.36 | Train MSE: 0.36 | Train RMSE: 0.60 |     Val. Loss: 0.34 | Val. MSE: 0.34 |  Val. RMSE: 0.58 |\n",
            "| Epoch: 03 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |     Val. Loss: 0.39 | Val. MSE: 0.39 |  Val. RMSE: 0.62 |\n",
            "| Epoch: 04 | Train Loss: 0.36 | Train MSE: 0.36 | Train RMSE: 0.60 |     Val. Loss: 0.37 | Val. MSE: 0.37 |  Val. RMSE: 0.61 |\n",
            "| Epoch: 05 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |     Val. Loss: 0.34 | Val. MSE: 0.34 |  Val. RMSE: 0.59 |\n",
            "| Epoch: 06 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |     Val. Loss: 0.34 | Val. MSE: 0.34 |  Val. RMSE: 0.58 |\n",
            "| Epoch: 07 | Train Loss: 0.34 | Train MSE: 0.34 | Train RMSE: 0.59 |     Val. Loss: 0.33 | Val. MSE: 0.33 |  Val. RMSE: 0.58 |\n",
            "| Epoch: 08 | Train Loss: 0.34 | Train MSE: 0.34 | Train RMSE: 0.59 |     Val. Loss: 0.33 | Val. MSE: 0.33 |  Val. RMSE: 0.57 |\n",
            "| Epoch: 09 | Train Loss: 0.36 | Train MSE: 0.36 | Train RMSE: 0.60 |     Val. Loss: 0.33 | Val. MSE: 0.33 |  Val. RMSE: 0.57 |\n",
            "| Epoch: 10 | Train Loss: 0.34 | Train MSE: 0.34 | Train RMSE: 0.59 |     Val. Loss: 0.33 | Val. MSE: 0.33 |  Val. RMSE: 0.57 |\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RgGo1GaDaxsu"
      },
      "source": [
        "Approach 1 Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UJQ1bqH13ZXx"
      },
      "source": [
        "# Save models\r\n",
        "torch.save(roberta_model, 'roberta-model.pt')\r\n",
        "torch.save(distil_model, 'distilbert-model.pt')"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "T_YyhDlPzSaP",
        "outputId": "3883e4d3-948e-4377-8726-d166d3541dfb"
      },
      "source": [
        "# Plot losses for both pre trained models\r\n",
        "epoch_losses_1, rmse_1 = zip(*performance_stats_distil)\r\n",
        "epoch_losses_2, rmse_2 = zip(*performance_stats_roberta)\r\n",
        "x = np.arange(epochs) + 1\r\n",
        "\r\n",
        "plt.figure(figsize=(10, 5))\r\n",
        "\r\n",
        "plt.subplot(1, 2, 1)\r\n",
        "plt.plot(x, epoch_losses_1, label='distil-bert')\r\n",
        "plt.plot(x, epoch_losses_2, label='roberta')\r\n",
        "plt.legend(loc='upper right')\r\n",
        "plt.xlabel('Epoch')\r\n",
        "plt.ylabel('Loss')\r\n",
        "plt.title('Pre-trained model losses')\r\n",
        "\r\n",
        "plt.subplot(1, 2, 2)\r\n",
        "plt.plot(x, rmse_1, label='distil-bert')\r\n",
        "plt.plot(x, rmse_2, label='roberta')\r\n",
        "plt.legend(loc='upper right')\r\n",
        "plt.xlabel('Epoch')\r\n",
        "plt.ylabel('RMSE')\r\n",
        "plt.title('Pre-trained model RMSE')\r\n",
        "plt.show()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tVgYgsuvcOZE",
        "outputId": "f5bfcf55-3294-49bd-d6b9-97efc31b8b8d"
      },
      "source": [
        "# Load model\r\n",
        "model = torch.load('roberta-model.pt')\r\n",
        "model.to(device)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertRegressionModel(\n",
              "  (bert): RobertaModel(\n",
              "    (embeddings): RobertaEmbeddings(\n",
              "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
              "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
              "      (token_type_embeddings): Embedding(1, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): RobertaEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): RobertaPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (linear1): Linear(in_features=768, out_features=32, bias=True)\n",
              "  (linear2): Linear(in_features=35, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ofd0fzAmNk87",
        "outputId": "0a7da934-393c-4179-fabc-ab3803d6ef6b"
      },
      "source": [
        "# Evaluate model on the competition data\r\n",
        "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\r\n",
        "\r\n",
        "# Set training and test data\r\n",
        "comp_ids = comp_test_df['id']\r\n",
        "comp_data = comp_test_df['original']\r\n",
        "comp_labels = comp_test_df['meanGrade']\r\n",
        "\r\n",
        "comp_data = Task1Dataset(tokenizer, comp_data, comp_labels)\r\n",
        "comp_loader = torch.utils.data.DataLoader(comp_data, batch_size=32)\r\n",
        "\r\n",
        "_,_,predictions,_ = eval(comp_loader, model)\r\n",
        "\r\n",
        "comp_preds = {'id': comp_ids, 'pred': predictions}\r\n",
        "comp_preds = pd.DataFrame(comp_preds)\r\n",
        "comp_preds.to_csv('pred_outputs.csv', index=False)\r\n",
        "print('Saved pred_outputs.csv')\r\n",
        "\r\n",
        "min_score = min(predictions)\r\n",
        "max_score = max(predictions)\r\n",
        "range = max_score - min_score\r\n",
        "print(f'Min score: {min_score}, Max score: {max_score}, Range: {range}')"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:32: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Saved pred_outputs.csv\n",
            "Min score: 0.8573441505432129, Max score: 1.0346357822418213, Range: 0.1772916316986084\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TSHxwXoviuma"
      },
      "source": [
        "### Aside: Using NER for Feature Engineering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFu6FcpAiuTo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "outputId": "b4e69062-624d-40ec-c459-ead7960625c8"
      },
      "source": [
        "import spacy\n",
        "\n",
        "stop_words = nltk.corpus.stopwords.words(\"english\")\n",
        "\n",
        "# spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# ps = nltk.stem.porter.PorterStemmer()\n",
        "# print([ps.stem(word) for word in txt])\n",
        "\n",
        "# lem = nltk.stem.wordnet.WordNetLemmatizer()\n",
        "# print([lem.lemmatize(word) for word in txt])\n",
        "\n",
        "# Test sentences\n",
        "sents = [\n",
        "  \"#WomensMarch against <Donald Trump/> around the world\",\n",
        "  \"' Disappeared ' Lawyer investigating in Egypt the death of Cambridge student , Giulio Regeni , re-appears in court , under <charges/> \",\n",
        "  \"' This is not the end ' : <John McCain/> warns Trump , torches Rand Paul on Syria missile strikes\"\n",
        "]\n",
        "\n",
        "# Map entities to an index, for representing as 1HV\n",
        "entities = []\n",
        "\n",
        "# Build model\n",
        "for s in sents:\n",
        "  pre_s = ' '.join([preprocess(t) for t in tokenize(s)])\n",
        "  r_sub = re.sub(r'[^\\w\\s]', '', str(s))\n",
        "\n",
        "  print()\n",
        "  print(f\"Original:       {s}\")\n",
        "  print(f\"Preprocessed:   {pre_s}\")\n",
        "  print(f\"New regex:      {r_sub}\")\n",
        "  print(f\"BERT Tokenized: {tokenizer.tokenize(pre_s)}\")\n",
        "\n",
        "  # NER\n",
        "  doc = ner(r_sub)\n",
        "  spacy.displacy.render(doc, style=\"ent\", jupyter=True)\n",
        "\n",
        "  # TODO: try and merge 'Trump' and 'Donald Trump' for PERSON entities\n",
        "  for e in doc.ents:\n",
        "    if e not in entities:\n",
        "        entities.append(e)\n",
        "\n",
        "  print()\n",
        "  \n",
        "ent2idx = {e: idx for (idx, e) in enumerate(entities)}\n",
        "print(ent2idx)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Original:       #WomensMarch against <Donald Trump/> around the world\n",
            "Preprocessed:   womensmarch against donald trump around the world\n",
            "New regex:      WomensMarch against Donald Trump around the world\n",
            "BERT Tokenized: ['women', '##sma', '##rch', 'against', 'donald', 'trump', 'around', 'the', 'world']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">WomensMarch against \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Donald Trump\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " around the world</div></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Original:       ' Disappeared ' Lawyer investigating in Egypt the death of Cambridge student , Giulio Regeni , re-appears in court , under <charges/> \n",
            "Preprocessed:   disappeared lawyer investigating in egypt the death of cambridge student giulio regeni re appears in court under charges\n",
            "New regex:       Disappeared  Lawyer investigating in Egypt the death of Cambridge student  Giulio Regeni  reappears in court  under charges \n",
            "BERT Tokenized: ['disappeared', 'lawyer', 'investigating', 'in', 'egypt', 'the', 'death', 'of', 'cambridge', 'student', 'gi', '##ulio', 'reg', '##eni', 're', 'appears', 'in', 'court', 'under', 'charges']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\"> Disappeared  \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Lawyer\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " investigating in \n",
              "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Egypt\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
              "</mark>\n",
              " the death of \n",
              "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Cambridge\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
              "</mark>\n",
              " student  \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Giulio Regeni\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              "  reappears in court  under charges </div></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Original:       ' This is not the end ' : <John McCain/> warns Trump , torches Rand Paul on Syria missile strikes\n",
            "Preprocessed:   this is not the end john mccain warns trump torches rand paul on syria missile strikes\n",
            "New regex:       This is not the end   John McCain warns Trump  torches Rand Paul on Syria missile strikes\n",
            "BERT Tokenized: ['this', 'is', 'not', 'the', 'end', 'john', 'mccain', 'warns', 'trump', 'torches', 'rand', 'paul', 'on', 'syria', 'missile', 'strikes']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\"> This is not the end   \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    John McCain\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " warns \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Trump\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              "  torches \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Rand Paul\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " on \n",
              "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Syria\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
              "</mark>\n",
              " missile strikes</div></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "{Donald Trump: 0, Lawyer: 1, Egypt: 2, Cambridge: 3, Giulio Regeni: 4, John McCain: 5, Trump: 6, Rand Paul: 7, Syria: 8}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rdeFaoc3lDpK"
      },
      "source": [
        "### Approach 2: No pre-trained representations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "46gm47T4lDpQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "351a448c-7eb5-4c8e-adaf-d55e9c7095a3"
      },
      "source": [
        "# TODO:\n",
        "# - remove stop words\n",
        "# - different norms\n",
        "# - pre: weigh query terms higher for certain\n",
        "\n",
        "train_and_dev = train_df['edit']\n",
        "\n",
        "training_data, dev_data, training_y, dev_y = train_test_split(train_df['edit'], train_df['meanGrade'],\n",
        "                                                                        test_size=(1-train_proportion),\n",
        "                                                                        random_state=42)\n",
        "\n",
        "# We train a Tf-idf model\n",
        "count_vect = CountVectorizer(stop_words='english')\n",
        "train_counts = count_vect.fit_transform(training_data)\n",
        "transformer = TfidfTransformer().fit(train_counts)\n",
        "train_counts = transformer.transform(train_counts)\n",
        "regression_model = LinearRegression().fit(train_counts, training_y)\n",
        "\n",
        "# Train predictions\n",
        "predicted_train = regression_model.predict(train_counts)\n",
        "\n",
        "# Calculate Tf-idf using train and dev, and validate model on dev:\n",
        "test_and_test_counts = count_vect.transform(train_and_dev)\n",
        "transformer = TfidfTransformer().fit(test_and_test_counts)\n",
        "\n",
        "test_counts = count_vect.transform(dev_data)\n",
        "\n",
        "test_counts = transformer.transform(test_counts)\n",
        "\n",
        "# Dev predictions\n",
        "predicted = regression_model.predict(test_counts)\n",
        "\n",
        "# We run the evaluation:\n",
        "print(\"\\nTrain performance:\")\n",
        "sse, mse = model_performance(predicted_train, training_y, True)\n",
        "\n",
        "print(\"\\nDev performance:\")\n",
        "sse, mse = model_performance(predicted, dev_y, True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Train performance:\n",
            "| MSE: 0.13 | RMSE: 0.37 |\n",
            "\n",
            "Dev performance:\n",
            "| MSE: 0.36 | RMSE: 0.60 |\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9HyHwHkUlDpa"
      },
      "source": [
        "#### Baseline for task 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7DA3q4o1lDpd",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "#Â Baseline for the task\n",
        "pred_baseline = torch.zeros(len(dev_y)) + np.mean(training_y)\n",
        "print(\"\\nBaseline performance:\")\n",
        "sse, mse = model_performance(pred_baseline, dev_y, True)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}