{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "colab": {
   "name": "task_1_main.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2TvyemfDlDmu"
   },
   "source": [
    "# NLP CW Task 2\n",
    "\n",
    "  - Approach 1, which can use use pre-trained embeddings / models\n",
    "  - Approach 2, which should not use any pre-trained embeddings or models\n",
    "\n",
    "#### Running your code:\n",
    "  - Your models should run automatically when running your colab file without further intervention\n",
    "  - For each task you should automatically output the performance of both models\n",
    "  - Your code should automatically download any libraries required\n",
    "\n",
    "#### Structure of your code:\n",
    "  - You are expected to use the 'train', 'eval' and 'model_performance' functions, although you may edit these as required\n",
    "  - Otherwise there are no restrictions on what you can do in your code\n",
    "\n",
    "#### Documentation:\n",
    "  - You are expected to produce a .README file summarising how you have approached both tasks\n",
    "  - Your .README file should explain how to replicate the different experiments mentioned in your report"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "LRWFk-kelDoA",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "16a4c391-745c-44eb-d954-d4f85abe213c"
   },
   "source": [
    "# Imports\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, random_split\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import codecs\n",
    "import tqdm\n",
    "import re"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Get word embeddings\n",
    "if not os.path.exists('glove.6B.50d.txt'):\n",
    "  !wget http://nlp.stanford.edu/data/glove.6B.zip\n",
    "  !unzip glove.6B.zip\n",
    "\n",
    "# Install packages that Colab does not provide automatically\n",
    "!pip install transformers\n",
    "from transformers import RobertaTokenizer, RobertaModel, BertPreTrainedModel, DistilBertModel, DistilBertTokenizer\n",
    "\n",
    "# Get test and train data files\n",
    "if not os.path.exists('dev.csv'):\n",
    "  !wget -q --show-progress https://raw.githubusercontent.com/matt-malarkey/nlp-cw-data/master/dev.csv\n",
    "  !wget -q --show-progress https://raw.githubusercontent.com/matt-malarkey/nlp-cw-data/master/train.csv"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "X09jt8VRlDoM"
   },
   "source": [
    "# Setting random seed and device\n",
    "SEED = 1\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "AqhlzLl6lDoO"
   },
   "source": [
    "# Load data\n",
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('dev.csv')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "3RCmF7xulDoP"
   },
   "source": [
    "# Number of epochs\n",
    "epochs = 10\n",
    "\n",
    "# Proportion of training data for train compared to dev\n",
    "train_proportion = 0.8"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "qAgZW6K1lDoR"
   },
   "source": [
    "# We define our training loop\n",
    "def train(train_iter, dev_iter, model, number_epoch):\n",
    "    \"\"\"\n",
    "    Training loop for the model, which calls on eval to evaluate after each epoch\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"Training model.\")\n",
    "\n",
    "    loss_fn = nn.MSELoss()\n",
    "    loss_fn = loss_fn.to(device)\n",
    "\n",
    "    for epoch in range(1, number_epoch+1):\n",
    "        model.train()\n",
    "\n",
    "        epoch_loss = 0\n",
    "        epoch_sse = 0\n",
    "        no_observations = 0  # Observations used for training so far\n",
    "\n",
    "        for batch in train_iter:\n",
    "            ids = batch['ids'].to(device).squeeze()\n",
    "            mask = batch['mask'].to(device).squeeze()\n",
    "            target = batch['target'].to(device, dtype=torch.float)\n",
    "            extra_features = batch['extra_features'].to(device)\n",
    "\n",
    "            predictions = model(ids, mask, extra_features).squeeze(1)\n",
    "            optimizer.zero_grad()\n",
    "            loss = loss_fn(predictions, target)\n",
    "\n",
    "            no_observations = no_observations + target.shape[0]\n",
    "            sse, __ = model_performance(predictions.detach().cpu().numpy(), target.detach().cpu().numpy())\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()*target.shape[0]\n",
    "            epoch_sse += sse\n",
    "\n",
    "        valid_loss, valid_mse, __, __ = eval(dev_iter, model)\n",
    "\n",
    "        epoch_loss, epoch_mse = epoch_loss / no_observations, epoch_sse / no_observations\n",
    "        print(f'| Epoch: {epoch:02} | Train Loss: {epoch_loss:.2f} | Train MSE: {epoch_mse:.2f} | Train RMSE: {epoch_mse**0.5:.2f} | \\\n",
    "        Val. Loss: {valid_loss:.2f} | Val. MSE: {valid_mse:.2f} |  Val. RMSE: {valid_mse**0.5:.2f} |')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "NzXeDgHmlDob"
   },
   "source": [
    "# We evaluate performance on our dev set\n",
    "def eval(data_iter, model):\n",
    "    \"\"\"\n",
    "    Evaluating model performance on the dev set\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    epoch_sse = 0\n",
    "    pred_all = []\n",
    "    trg_all = []\n",
    "    no_observations = 0\n",
    "    loss_fn = nn.MSELoss()\n",
    "    loss_fn = loss_fn.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in data_iter:\n",
    "            ids = batch['ids'].to(device).squeeze()\n",
    "            mask = batch['mask'].to(device).squeeze()\n",
    "            target = batch['target'].to(device, dtype=torch.float)\n",
    "            extra_features = batch['extra_features'].to(device)\n",
    "\n",
    "            predictions = model(ids, mask, extra_features).squeeze(1)\n",
    "\n",
    "            loss = loss_fn(predictions, target)\n",
    "\n",
    "            # We get the mse\n",
    "            pred, trg = predictions.detach().cpu().numpy(), target.detach().cpu().numpy()\n",
    "            sse, __ = model_performance(pred, trg)\n",
    "\n",
    "            no_observations = no_observations + target.shape[0]\n",
    "            epoch_loss += loss.item()*target.shape[0]\n",
    "            epoch_sse += sse\n",
    "            pred_all.extend(pred)\n",
    "            trg_all.extend(trg)\n",
    "\n",
    "    return epoch_loss/no_observations, epoch_sse/no_observations, np.array(pred_all), np.array(trg_all)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "2_22fHHElDog"
   },
   "source": [
    "# How we print the model performance\n",
    "def model_performance(output, target, print_output=False):\n",
    "    \"\"\"\n",
    "    Returns SSE and MSE per batch (printing the MSE and the RMSE)\n",
    "    \"\"\"\n",
    "    sq_error = (output - target)**2\n",
    "\n",
    "    sse = np.sum(sq_error)\n",
    "    mse = np.mean(sq_error)\n",
    "    rmse = np.sqrt(mse)\n",
    "\n",
    "    if print_output:\n",
    "        print(f'| MSE: {mse:.2f} | RMSE: {rmse:.2f} |')\n",
    "\n",
    "    return sse, mse"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Preprocessing"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Pattern to match words and multiword tags\n",
    "# See https://regex101.com/r/a2cWZL/1 for example\n",
    "# TOKEN_PATTERN = re.compile(\"[A-Za-z#]+|<[A-Za-z#]+\\s[A-Za-z]+\\/>\")\n",
    "\n",
    "# Patten to match only words\n",
    "TOKEN_PATTERN = re.compile(\"\\w+\")\n",
    "\n",
    "# TODO: processing of:\n",
    "# - hashtags,\n",
    "# - words with a \"-\" in between them\n",
    "# - punctuation\n",
    "# - entity names\n",
    "\n",
    "def tokenize(sentence):\n",
    "  return TOKEN_PATTERN.findall(sentence)\n",
    "\n",
    "# Remove angle brackets and lowercase\n",
    "def pre(word):\n",
    "  if len(word) > 2 and word[0] == '<' and word[-2] == '/' and word[-1] == '>' :\n",
    "     word = word[1:-2]\n",
    "  return word.lower()\n",
    "\n",
    "def create_vocab(data):\n",
    "  \"\"\"\n",
    "  Creating a corpus of all the tokens used\n",
    "  \"\"\"\n",
    "  # Let us put the tokenized corpus in a list\n",
    "  tokenized_corpus = [[pre(t) for t in tokenize(s)] for s in data]\n",
    "\n",
    "  # Create single list of all vocabulary\n",
    "  vocabulary = []\n",
    "  for sentence in tokenized_corpus:\n",
    "    for token in sentence:\n",
    "      if token not in vocabulary:\n",
    "        vocabulary.append(token)\n",
    "\n",
    "  return vocabulary, tokenized_corpus"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def pre_process_headline(headline):\n",
    "  extra_features = [0]\n",
    "  if 'Trump' in headline:\n",
    "    extra_features[0] = 1\n",
    "  return extra_features\n",
    "\n",
    "# Inherits from Dataset class so the DataLoader can use it\n",
    "class Task1Dataset(Dataset):\n",
    "\n",
    "    def __init__(self, tokenizer, train_data, labels):\n",
    "        self.x_train = train_data\n",
    "        self.y_train = labels\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y_train)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        headline = self.x_train[item]\n",
    "        target = self.y_train[item]\n",
    "        encoding = self.tokenizer.encode_plus(headline, return_tensors='pt',\n",
    "                                              padding='max_length', truncation=True,\n",
    "                                              max_length=128, pad_to_max_length=True)\n",
    "        ids = encoding['input_ids']\n",
    "        mask = encoding['attention_mask']\n",
    "\n",
    "        extra_features = pre_process_headline(headline)\n",
    "\n",
    "        return {\n",
    "            'ids': torch.tensor(ids),\n",
    "            'mask': torch.tensor(mask),\n",
    "            'target': torch.tensor(target),\n",
    "            'extra_features': torch.tensor(extra_features)\n",
    "        }"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "sWaxTh2UlDoy"
   },
   "source": [
    "class DistilBertRegressionModel(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(DistilBertRegressionModel, self).__init__()\n",
    "\n",
    "    self.bert = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
    "    self.num_extra_features = 1\n",
    "    self.linear1 = nn.Linear(768, 32)\n",
    "    self.linear2 = nn.Linear(32 + self.num_extra_features, 1)\n",
    "    self.loss = nn.MSELoss()\n",
    "\n",
    "  def forward(self, ids, mask, extra_features):\n",
    "        embeddings = self.bert(input_ids=ids, attention_mask=mask)[0]\n",
    "        x = self.linear1(embeddings[:, 0])\n",
    "        concat_features = torch.cat([x, extra_features], dim=1)\n",
    "        x = self.linear2(concat_features)\n",
    "        return x"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "scrolled": true,
    "id": "bp9d32sOlDo6",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 469
    },
    "outputId": "b404703e-73a7-4668-eb83-f3b043d69383"
   },
   "source": [
    "## Approach 1 code, using functions defined above:\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Initialise RoBERTa model and tokenizer\n",
    "model = DistilBertRegressionModel().to(device)\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "# We set our training data and test data\n",
    "training_data = train_df['original1']\n",
    "test_data = test_df['original1']\n",
    "\n",
    "train_and_dev = Task1Dataset(tokenizer, training_data, train_df['meanGrade1'])\n",
    "\n",
    "train_examples = round(len(train_and_dev)*train_proportion)\n",
    "dev_examples = len(train_and_dev) - train_examples\n",
    "\n",
    "train_dataset, dev_dataset = random_split(train_and_dev, (train_examples, dev_examples))\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, shuffle=True, batch_size=BATCH_SIZE)\n",
    "dev_loader = torch.utils.data.DataLoader(dev_dataset, batch_size=BATCH_SIZE)\n",
    "\n",
    "print(\"Dataloaders created.\")\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "train(train_loader, dev_loader, model, epochs)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rdeFaoc3lDpK"
   },
   "source": [
    "#### Approach 2: No pre-trained representations"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "46gm47T4lDpQ",
    "outputId": "200c6ad7-aa53-4e25-8939-11b46e6e6759"
   },
   "source": [
    "train_and_dev = train_df['edit']\n",
    "\n",
    "training_data, dev_data, training_y, dev_y = train_test_split(train_df['edit'], train_df['meanGrade'],\n",
    "                                                                        test_size=(1-train_proportion),\n",
    "                                                                        random_state=42)\n",
    "\n",
    "# We train a Tf-idf model\n",
    "count_vect = CountVectorizer(stop_words='english')\n",
    "train_counts = count_vect.fit_transform(training_data)\n",
    "transformer = TfidfTransformer().fit(train_counts)\n",
    "train_counts = transformer.transform(train_counts)\n",
    "regression_model = LinearRegression().fit(train_counts, training_y)\n",
    "\n",
    "# Train predictions\n",
    "predicted_train = regression_model.predict(train_counts)\n",
    "\n",
    "# Calculate Tf-idf using train and dev, and validate model on dev:\n",
    "test_and_test_counts = count_vect.transform(train_and_dev)\n",
    "transformer = TfidfTransformer().fit(test_and_test_counts)\n",
    "\n",
    "test_counts = count_vect.transform(dev_data)\n",
    "\n",
    "test_counts = transformer.transform(test_counts)\n",
    "\n",
    "# Dev predictions\n",
    "predicted = regression_model.predict(test_counts)\n",
    "\n",
    "# We run the evaluation:\n",
    "print(\"\\nTrain performance:\")\n",
    "sse, mse = model_performance(predicted_train, training_y, True)\n",
    "\n",
    "print(\"\\nDev performance:\")\n",
    "sse, mse = model_performance(predicted, dev_y, True)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9HyHwHkUlDpa"
   },
   "source": [
    "#### Baseline for task 2"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "7DA3q4o1lDpd",
    "outputId": "fa88780f-7ed0-4c2b-f2cf-bc0b2883626d",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# Baseline for the task\n",
    "pred_baseline = torch.zeros(len(dev_y)) + np.mean(training_y)\n",
    "print(\"\\nBaseline performance:\")\n",
    "sse, mse = model_performance(pred_baseline, dev_y, True)"
   ],
   "execution_count": null,
   "outputs": []
  }
 ]
}